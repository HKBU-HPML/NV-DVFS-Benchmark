"arg:" 
[applications\convolutionSeparable] - Starting...
gpuDeviceInit() CUDA Device [1]: "GeForce GTX 980
Image Width x Height = 3072 x 3072

Allocating and initializing host arrays...
Allocating and initializing CUDA arrays...
Running GPU convolution (100 identical iterations)...

Adjust Iters to 3484 for meeting time requirement 10 secs.
iterated 3484, average time is 2.848320 msec.

Reading back GPU results...

Checking the results...
 ...running convolutionRowCPU()
 ...running convolutionColumnCPU()
 ...comparing the results
 ...Relative L2 norm: 0.000000E+000

Shutting down...
Test passed
[applications/convolutionSeparable] - Starting...
gpuDeviceInit() CUDA Device [1]: "GeForce GTX 980
Image Width x Height = 3072 x 3072

Allocating and initializing host arrays...
Allocating and initializing CUDA arrays...
Running GPU convolution (50 identical iterations)...

iterated 50, average time is 2.852329 msec.

Reading back GPU results...

Checking the results...
 ...running convolutionRowCPU()
 ...running convolutionColumnCPU()
 ...comparing the results
 ...Relative L2 norm: 0.000000E+000

Shutting down...
Test passed
==34512== NVPROF is profiling process 34512, command: applications/convolutionSeparable -device=1 -iters=50
==34512== Warning: Unified Memory Profiling is not supported on the current configuration because a pair of devices without peer-to-peer support is detected on this multi-GPU setup. When peer mappings are not available, system falls back to using zero-copy memory. It can cause kernels, which access unified memory, to run slower. More details can be found at: http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#um-managed-memory
==34512== Profiling application: applications/convolutionSeparable -device=1 -iters=50
==34512== Profiling result:
Time(%)      Time     Calls       Avg       Min       Max  Name
 41.96%  73.468ms        51  1.4406ms  1.4354ms  1.4463ms  convolutionColumnsKernel(float*, float*, int, int, int)
 39.14%  68.539ms        51  1.3439ms  1.3409ms  1.3534ms  convolutionRowsKernel(float*, float*, int, int, int)
  9.74%  17.064ms         1  17.064ms  17.064ms  17.064ms  [CUDA memcpy DtoH]
  9.16%  16.040ms         2  8.0202ms  2.4640us  16.038ms  [CUDA memcpy HtoD]

==34512== API calls:
Time(%)      Time     Calls       Avg       Min       Max  Name
 47.72%  226.74ms         3  75.579ms  7.0591ms  212.55ms  cudaMalloc
 30.80%  146.37ms        51  2.8700ms  2.8495ms  3.5891ms  cudaThreadSynchronize
 12.58%  59.757ms         1  59.757ms  59.757ms  59.757ms  cudaDeviceReset
  6.96%  33.066ms         2  16.533ms  15.635ms  17.431ms  cudaMemcpy
  0.51%  2.4293ms        51  47.633us  46.903us  51.167us  cudaEventSynchronize
  0.38%  1.8179ms         3  605.96us  532.14us  750.46us  cudaFree
  0.34%  1.6135ms       102  15.818us  13.928us  59.411us  cudaLaunch
  0.22%  1.0600ms       182  5.8240us       0ns  289.38us  cuDeviceGetAttribute
  0.16%  781.73us       102  7.6640us  5.6850us  11.371us  cudaEventRecord
  0.12%  591.84us         1  591.84us  591.84us  591.84us  cudaGetDeviceProperties
  0.10%  484.67us        51  9.5030us  9.0960us  10.518us  cudaEventElapsedTime
  0.04%  177.95us         2  88.974us  69.076us  108.87us  cuDeviceGetName
  0.02%  98.074us       510     192ns       0ns  1.4210us  cudaSetupArgument
  0.01%  45.198us         1  45.198us  45.198us  45.198us  cudaMemcpyToSymbol
  0.01%  37.805us       102     370ns       0ns  3.4110us  cudaConfigureCall
  0.01%  30.135us       102     295ns       0ns     569ns  cudaGetLastError
  0.00%  16.487us         2  8.2430us  1.1370us  15.350us  cudaEventCreate
  0.00%  14.780us         2  7.3900us  7.3900us  7.3900us  cudaDeviceSynchronize
  0.00%  12.223us         2  6.1110us  5.6850us  6.5380us  cuDeviceTotalMem
  0.00%  11.655us         1  11.655us  11.655us  11.655us  cudaSetDevice
  0.00%  4.2620us         3  1.4200us     568ns  2.8420us  cuDeviceGetCount
  0.00%  3.1260us         6     521ns     284ns  1.1370us  cuDeviceGet
  0.00%  1.1370us         1  1.1370us  1.1370us  1.1370us  cudaGetDeviceCount
