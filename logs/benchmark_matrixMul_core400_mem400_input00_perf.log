"arg:-wA=1024 -hA=1024 -wB=1024 -hB=1024" 
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
Adjust Iters to 1002 for meeting time requirement 10 secs.
iterated 1002, average time is 9.999461 msec
Performance= 214.76 GFlop/s, Time= 9.999 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 10.036304 msec
Performance= 213.97 GFlop/s, Time= 10.036 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==46224== NVPROF is profiling process 46224, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==46224== Warning: Unified Memory Profiling is not supported on the current configuration because a pair of devices without peer-to-peer support is detected on this multi-GPU setup. When peer mappings are not available, system falls back to using zero-copy memory. It can cause kernels, which access unified memory, to run slower. More details can be found at: http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#um-managed-memory
==46224== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==46224== Profiling result:
Time(%)      Time     Calls       Avg       Min       Max  Name
 98.92%  517.56ms        52  9.9531ms  9.8964ms  9.9993ms  void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
  0.63%  3.2963ms         2  1.6481ms  1.6049ms  1.6914ms  [CUDA memcpy HtoD]
  0.45%  2.3485ms         1  2.3485ms  2.3485ms  2.3485ms  [CUDA memcpy DtoH]

==46224== API calls:
Time(%)      Time     Calls       Avg       Min       Max  Name
 63.77%  511.75ms        51  10.034ms  9.9723ms  10.083ms  cudaThreadSynchronize
 24.17%  193.94ms         3  64.646ms  1.1143ms  191.70ms  cudaMalloc
  8.92%  71.605ms         1  71.605ms  71.605ms  71.605ms  cudaDeviceReset
  1.34%  10.761ms         3  3.5869ms  7.3900us  10.736ms  cudaDeviceSynchronize
  0.77%  6.2066ms         3  2.0689ms  1.2778ms  2.9447ms  cudaMemcpy
  0.43%  3.4160ms        51  66.980us  56.853us  212.63us  cudaEventSynchronize
  0.13%  1.0288ms       182  5.6520us       0ns  286.54us  cuDeviceGetAttribute
  0.11%  908.22us       102  8.9040us  5.1160us  17.341us  cudaEventRecord
  0.11%  897.42us        52  17.258us  15.066us  55.716us  cudaLaunch
  0.07%  574.22us         1  574.22us  574.22us  574.22us  cudaGetDeviceProperties
  0.06%  468.75us         3  156.25us  118.82us  183.64us  cudaFree
  0.06%  449.99us        51  8.8230us  7.9590us  20.183us  cudaEventElapsedTime
  0.02%  179.09us       260     688ns       0ns  11.655us  cudaSetupArgument
  0.02%  160.04us         2  80.021us  70.498us  89.544us  cuDeviceGetName
  0.01%  77.889us        52  1.4970us     284ns  11.371us  cudaConfigureCall
  0.00%  13.076us         1  13.076us  13.076us  13.076us  cudaSetDevice
  0.00%  10.802us         2  5.4010us  5.4010us  5.4010us  cuDeviceTotalMem
  0.00%  7.6750us         2  3.8370us  1.1370us  6.5380us  cudaEventCreate
  0.00%  3.1260us         3  1.0420us     284ns  2.5580us  cuDeviceGetCount
  0.00%  2.5590us         1  2.5590us  2.5590us  2.5590us  cudaGetDevice
  0.00%  1.9880us         6     331ns       0ns     568ns  cuDeviceGet
