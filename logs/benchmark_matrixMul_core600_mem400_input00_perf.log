"arg:-wA=1024 -hA=1024 -wB=1024 -hB=1024" 
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
Adjust Iters to 1326 for meeting time requirement 10 secs.
iterated 1326, average time is 7.578210 msec
Performance= 283.38 GFlop/s, Time= 7.578 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 7.589800 msec
Performance= 282.94 GFlop/s, Time= 7.590 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==51780== NVPROF is profiling process 51780, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==51780== Warning: Unified Memory Profiling is not supported on the current configuration because a pair of devices without peer-to-peer support is detected on this multi-GPU setup. When peer mappings are not available, system falls back to using zero-copy memory. It can cause kernels, which access unified memory, to run slower. More details can be found at: http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#um-managed-memory
==51780== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==51780== Profiling result:
Time(%)      Time     Calls       Avg       Min       Max  Name
 98.59%  391.20ms        52  7.5230ms  7.4379ms  7.6004ms  void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
  0.81%  3.2334ms         2  1.6167ms  1.5755ms  1.6579ms  [CUDA memcpy HtoD]
  0.60%  2.3813ms         1  2.3813ms  2.3813ms  2.3813ms  [CUDA memcpy DtoH]

==51780== API calls:
Time(%)      Time     Calls       Avg       Min       Max  Name
 58.10%  387.34ms        51  7.5948ms  7.5074ms  7.7283ms  cudaThreadSynchronize
 28.63%  190.86ms         3  63.618ms  1.0902ms  188.66ms  cudaMalloc
  9.95%  66.329ms         1  66.329ms  66.329ms  66.329ms  cudaDeviceReset
  1.26%  8.3741ms         3  2.7914ms  7.1070us  8.3500ms  cudaDeviceSynchronize
  0.95%  6.3269ms         3  2.1090ms  1.2434ms  3.1448ms  cudaMemcpy
  0.42%  2.8219ms        51  55.331us  29.279us  94.376us  cudaEventSynchronize
  0.16%  1.0418ms       182  5.7240us       0ns  280.00us  cuDeviceGetAttribute
  0.14%  959.96us        52  18.460us  14.497us  86.417us  cudaLaunch
  0.12%  766.66us       102  7.5160us  4.8320us  20.183us  cudaEventRecord
  0.08%  561.42us         1  561.42us  561.42us  561.42us  cudaGetDeviceProperties
  0.07%  467.90us         3  155.97us  118.54us  185.34us  cudaFree
  0.06%  416.17us        51  8.1600us  7.6750us  19.898us  cudaEventElapsedTime
  0.02%  150.38us         2  75.188us  70.782us  79.594us  cuDeviceGetName
  0.02%  131.90us       260     507ns       0ns  11.654us  cudaSetupArgument
  0.01%  35.249us        52     677ns     284ns  11.939us  cudaConfigureCall
  0.00%  12.792us         1  12.792us  12.792us  12.792us  cudaSetDevice
  0.00%  11.371us         2  5.6850us  5.4010us  5.9700us  cuDeviceTotalMem
  0.00%  7.6750us         2  3.8370us  1.1370us  6.5380us  cudaEventCreate
  0.00%  3.4130us         3  1.1370us     285ns  2.5590us  cuDeviceGetCount
  0.00%  2.5590us         1  2.5590us  2.5590us  2.5590us  cudaGetDevice
  0.00%  2.2740us         6     379ns       0ns     569ns  cuDeviceGet
