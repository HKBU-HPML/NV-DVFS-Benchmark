"arg:-wA=1024 -hA=1024 -wB=1024 -hB=1024" 
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
Adjust Iters to 1455 for meeting time requirement 10 secs.
iterated 1455, average time is 6.889462 msec
Performance= 311.71 GFlop/s, Time= 6.889 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 20.639243 msec.
GPU total   time: 1031.962173 ms
GPU average time: 20.639243 ms
Performance= 104.05 GFlop/s, Time= 20.639 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==71388== NVPROF is profiling process 71388, command: applications/matrixMul(Global) -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==71388== Warning: Unified Memory Profiling is not supported on the current configuration because a pair of devices without peer-to-peer support is detected on this multi-GPU setup. When peer mappings are not available, system falls back to using zero-copy memory. It can cause kernels, which access unified memory, to run slower. More details can be found at: http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#um-managed-memory
==71388== Profiling application: applications/matrixMul(Global) -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==71388== Profiling result:
Time(%)      Time     Calls       Avg       Min       Max  Name
 99.52%  1.06784s        52  20.535ms  20.475ms  20.703ms  void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
  0.30%  3.2514ms         2  1.6257ms  1.5781ms  1.6732ms  [CUDA memcpy HtoD]
  0.17%  1.8737ms         1  1.8737ms  1.8737ms  1.8737ms  [CUDA memcpy DtoH]

==71388== API calls:
Time(%)      Time     Calls       Avg       Min       Max  Name
 77.74%  1.05224s        51  20.632ms  20.552ms  20.797ms  cudaThreadSynchronize
 14.48%  195.96ms         3  65.320ms  1.0919ms  193.77ms  cudaMalloc
  5.07%  68.688ms         1  68.688ms  68.688ms  68.688ms  cudaDeviceReset
  1.57%  21.282ms         3  7.0940ms  7.1070us  21.268ms  cudaDeviceSynchronize
  0.42%  5.6620ms         3  1.8873ms  1.2525ms  2.4646ms  cudaMemcpy
  0.31%  4.1886ms        51  82.130us  44.345us  200.12us  cudaEventSynchronize
  0.11%  1.4247ms       182  7.8280us       0ns  585.87us  cuDeviceGetAttribute
  0.08%  1.0359ms        52  19.920us  16.487us  58.558us  cudaLaunch
  0.07%  944.04us       102  9.2550us  5.6850us  27.005us  cudaEventRecord
  0.05%  668.87us         1  668.87us  668.87us  668.87us  cudaGetDeviceProperties
  0.04%  527.88us         3  175.96us  142.70us  200.12us  cudaFree
  0.04%  517.93us        51  10.155us  8.5280us  21.604us  cudaEventElapsedTime
  0.02%  262.66us         2  131.33us  89.543us  173.12us  cuDeviceGetName
  0.00%  62.536us       260     240ns       0ns  1.1370us  cudaSetupArgument
  0.00%  32.121us        52     617ns     284ns  4.5480us  cudaConfigureCall
  0.00%  16.488us         1  16.488us  16.488us  16.488us  cudaSetDevice
  0.00%  11.370us         2  5.6850us  5.6850us  5.6850us  cuDeviceTotalMem
  0.00%  7.1070us         2  3.5530us  1.1370us  5.9700us  cudaEventCreate
  0.00%  2.8420us         3     947ns     284ns  2.2740us  cuDeviceGetCount
  0.00%  2.5580us         1  2.5580us  2.5580us  2.5580us  cudaGetDevice
  0.00%  2.2730us         6     378ns     284ns     569ns  cuDeviceGet
