[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 15, average time is 9.548928 msec
Performance= 224.89 GFlop/s, Time= 9.549 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==11280== NVPROF is profiling process 11280, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==11280== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==11280== Profiling result:
   Start  Duration            Grid Size      Block Size     Regs*    SSMem*    DSMem*      Size  Throughput           Device   Context    Stream  Name
200.42ms  1.4479ms                    -               -         -         -         -  4.0000MB  2.6978GB/s  GeForce GTX 980         1         7  [CUDA memcpy HtoD]
202.19ms  1.5267ms                    -               -         -         -         -  4.0000MB  2.5587GB/s  GeForce GTX 980         1         7  [CUDA memcpy HtoD]
203.73ms  9.4353ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [114]
213.28ms  9.4402ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [125]
222.90ms  9.4342ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [138]
232.53ms  9.4533ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [150]
242.35ms  9.4364ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [162]
251.98ms  9.4441ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [174]
261.56ms  9.4405ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [186]
271.20ms  9.4444ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [198]
280.81ms  9.4388ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [210]
290.44ms  9.4382ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [222]
300.05ms  9.4333ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [234]
309.85ms  9.4446ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [246]
319.45ms  9.4446ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [258]
329.09ms  9.4288ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [270]
338.71ms  9.4492ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [282]
348.36ms  9.4344ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [294]
357.99ms  9.4346ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [306]
367.79ms  2.2926ms                    -               -         -         -         -  4.0000MB  1.7038GB/s  GeForce GTX 980         1         7  [CUDA memcpy DtoH]

Regs: Number of registers used per CUDA thread. This number includes registers used internally by the CUDA driver and/or tools and can be more than what the compiler shows.
SSMem: Static shared memory allocated per CUDA block.
DSMem: Dynamic shared memory allocated per CUDA block.
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 15, average time is 16.761683 msec
Performance= 128.12 GFlop/s, Time= 16.762 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==10148== NVPROF is profiling process 10148, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==10148== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==10148== Profiling result:
==10148== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         17                        achieved_occupancy                        Achieved Occupancy    0.990780    0.994639    0.992586
         17                             sm_efficiency                   Multiprocessor Activity      98.54%      98.98%      98.74%
         17                 warp_execution_efficiency                 Warp Execution Efficiency     100.00%     100.00%     100.00%
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 15, average time is 40.481741 msec
Performance= 53.05 GFlop/s, Time= 40.482 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==15116== NVPROF is profiling process 15116, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==15116== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==15116== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==15116== Profiling result:
==15116== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         17                  eligible_warps_per_cycle           Eligible Warps Per Active Cycle    1.878892    1.883977    1.880898
         17                    dram_read_transactions           Device Memory Read Transactions     4326295     4338391     4331173
         17                      dram_read_throughput             Device Memory Read Throughput  13.702GB/s  13.736GB/s  13.717GB/s
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 15, average time is 37.926306 msec
Performance= 56.62 GFlop/s, Time= 37.926 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==12496== NVPROF is profiling process 12496, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==12496== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==12496== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==12496== Profiling result:
==12496== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         17                   dram_write_transactions          Device Memory Write Transactions      157301      161843      161243
         17                     dram_write_throughput            Device Memory Write Throughput  509.88MB/s  526.62MB/s  521.66MB/s
         17                      l2_read_transactions                      L2 Read Transactions     8388679     8389078     8388877
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 15, average time is 42.183610 msec
Performance= 50.91 GFlop/s, Time= 42.184 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==10576== NVPROF is profiling process 10576, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==10576== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==10576== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==10576== Profiling result:
==10576== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         17                        l2_read_throughput                     L2 Throughput (Reads)  26.541GB/s  26.593GB/s  26.566GB/s
         17                     l2_write_transactions                     L2 Write Transactions      131078      131359      131094
         17                       l2_write_throughput                    L2 Throughput (Writes)  424.68MB/s  426.07MB/s  424.39MB/s
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 15, average time is 12.212983 msec
Performance= 175.84 GFlop/s, Time= 12.213 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==13596== NVPROF is profiling process 13596, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==13596== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==13596== Profiling result:
==13596== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         17                  shared_load_transactions                  Shared Load Transactions    50331648    50331648    50331648
         17                    shared_load_throughput             Shared Memory Load Throughput  636.70GB/s  638.90GB/s  637.72GB/s
         17                 shared_store_transactions                 Shared Store Transactions     2097152     2097152     2097152
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 15, average time is 15.500126 msec
Performance= 138.55 GFlop/s, Time= 15.500 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==15200== NVPROF is profiling process 15200, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==15200== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==15200== Profiling result:
==15200== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         17                   shared_store_throughput            Shared Memory Store Throughput  26.516GB/s  26.580GB/s  26.547GB/s
         17                         branch_efficiency                         Branch Efficiency     100.00%     100.00%     100.00%
         17                               cf_executed        Executed Control-Flow Instructions     1114112     1114112     1114112
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 15, average time is 424.399801 msec
Performance= 5.06 GFlop/s, Time= 424.400 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==14412== NVPROF is profiling process 14412, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==14412== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==14412== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==14412== Profiling result:
==14412== Metric result:
Invocations                               Metric Name                            Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         17                                 cf_issued              Issued Control-Flow Instructions     1114112     1114112     1114112
         17                             flop_count_sp   Floating Point Operations(Single Precision)  2147483648  2147483648  2147483648
         17                        flop_sp_efficiency                  FLOP Efficiency(Peak Single)      13.72%      13.77%      13.75%
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 15, average time is 58.534081 msec
Performance= 36.69 GFlop/s, Time= 58.534 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==14748== NVPROF is profiling process 14748, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==14748== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==14748== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==14748== Profiling result:
==14748== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         17                            gld_throughput                    Global Load Throughput  26.540GB/s  26.629GB/s  26.570GB/s
         17                          gld_transactions                  Global Load Transactions    16777216    16777216    16777216
         17                            gst_throughput                   Global Store Throughput  424.64MB/s  426.07MB/s  424.39MB/s
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 15, average time is 15.621739 msec
Performance= 137.47 GFlop/s, Time= 15.622 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==8300== NVPROF is profiling process 8300, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==8300== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==8300== Profiling result:
==8300== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         17                          gst_transactions                 Global Store Transactions      131072      131072      131072
         17                               inst_issued                       Instructions Issued    97850170    97850694    97850431
         17                             inst_per_warp                     Instructions per warp  2.9860e+03  2.9860e+03  2.9860e+03
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 15, average time is 13.098697 msec
Performance= 163.95 GFlop/s, Time= 13.099 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==15292== NVPROF is profiling process 15292, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==15292== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==15292== Profiling result:
==15292== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         17                                       ipc                              Executed IPC    1.622730    1.626033    1.624491
