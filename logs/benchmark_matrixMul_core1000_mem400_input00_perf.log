"arg:-wA=1024 -hA=1024 -wB=1024 -hB=1024" 
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
Adjust Iters to 1488 for meeting time requirement 10 secs.
iterated 1488, average time is 6.722237 msec
Performance= 319.46 GFlop/s, Time= 6.722 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 6.706246 msec
Performance= 320.22 GFlop/s, Time= 6.706 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==64120== NVPROF is profiling process 64120, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==64120== Warning: Unified Memory Profiling is not supported on the current configuration because a pair of devices without peer-to-peer support is detected on this multi-GPU setup. When peer mappings are not available, system falls back to using zero-copy memory. It can cause kernels, which access unified memory, to run slower. More details can be found at: http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#um-managed-memory
==64120== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==64120== Profiling result:
Time(%)      Time     Calls       Avg       Min       Max  Name
 98.37%  345.26ms        52  6.6396ms  6.6184ms  6.6911ms  void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
  0.92%  3.2338ms         2  1.6169ms  1.5761ms  1.6577ms  [CUDA memcpy HtoD]
  0.71%  2.4923ms         1  2.4923ms  2.4923ms  2.4923ms  [CUDA memcpy DtoH]

==64120== API calls:
Time(%)      Time     Calls       Avg       Min       Max  Name
 56.75%  342.12ms        51  6.7083ms  6.6717ms  6.7573ms  cudaThreadSynchronize
 30.87%  186.10ms         3  62.032ms  1.0899ms  183.91ms  cudaMalloc
  8.83%  53.251ms         1  53.251ms  53.251ms  53.251ms  cudaDeviceReset
  1.24%  7.4742ms         3  2.4914ms  7.1060us  7.4497ms  cudaDeviceSynchronize
  1.06%  6.3948ms         3  2.1316ms  1.2400ms  3.2204ms  cudaMemcpy
  0.45%  2.6974ms        51  52.889us  29.279us  120.53us  cudaEventSynchronize
  0.23%  1.3696ms       182  7.5250us       0ns  453.69us  cuDeviceGetAttribute
  0.14%  843.70us        52  16.224us  14.213us  52.874us  cudaLaunch
  0.13%  775.76us       102  7.6050us  5.1160us  17.340us  cudaEventRecord
  0.09%  554.32us         1  554.32us  554.32us  554.32us  cudaGetDeviceProperties
  0.08%  466.19us         3  155.40us  118.54us  185.06us  cudaFree
  0.07%  413.60us        51  8.1090us  7.6750us  19.045us  cudaEventElapsedTime
  0.02%  144.97us         2  72.487us  68.223us  76.751us  cuDeviceGetName
  0.02%  128.20us       260     493ns       0ns  11.371us  cudaSetupArgument
  0.01%  35.534us        52     683ns     284ns  11.371us  cudaConfigureCall
  0.00%  15.635us         2  7.8170us  5.4010us  10.234us  cuDeviceTotalMem
  0.00%  13.077us         1  13.077us  13.077us  13.077us  cudaSetDevice
  0.00%  6.2540us         2  3.1270us     853ns  5.4010us  cudaEventCreate
  0.00%  3.4090us         6     568ns     284ns  1.4210us  cuDeviceGet
  0.00%  3.1270us         3  1.0420us     284ns  2.5590us  cuDeviceGetCount
  0.00%  2.5590us         1  2.5590us  2.5590us  2.5590us  cudaGetDevice
