[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 30, average time is 9.866740 msec
Performance= 217.65 GFlop/s, Time= 9.867 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==2868== NVPROF is profiling process 2868, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=30
==2868== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=30
==2868== Profiling result:
   Start  Duration            Grid Size      Block Size     Regs*    SSMem*    DSMem*      Size  Throughput           Device   Context    Stream  Name
216.13ms  1.6441ms                    -               -         -         -         -  4.0000MB  2.3759GB/s  GeForce GTX 980         1         7  [CUDA memcpy HtoD]
218.37ms  1.5494ms                    -               -         -         -         -  4.0000MB  2.5212GB/s  GeForce GTX 980         1         7  [CUDA memcpy HtoD]
219.94ms  9.5088ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [114]
229.56ms  9.5056ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [125]
239.26ms  9.5122ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [138]
249.68ms  9.5045ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [150]
259.47ms  9.5778ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [162]
269.91ms  9.4982ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [174]
279.71ms  9.5041ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [186]
289.41ms  9.5770ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [198]
299.94ms  9.5028ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [210]
309.75ms  9.5749ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [222]
319.52ms  9.5182ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [234]
329.23ms  9.5222ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [246]
339.64ms  9.5025ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [258]
349.43ms  9.5210ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [270]
359.86ms  9.5078ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [282]
369.64ms  9.5016ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [294]
379.29ms  9.5066ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [306]
389.68ms  9.5903ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [318]
399.53ms  9.4985ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [330]
409.25ms  9.5036ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [342]
419.67ms  9.5186ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [354]
429.45ms  9.5096ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [366]
439.13ms  9.5165ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [378]
449.57ms  9.5263ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [390]
459.36ms  9.5060ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [402]
469.73ms  9.4988ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [414]
479.51ms  9.5042ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [426]
489.19ms  9.5089ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [438]
499.50ms  9.5228ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [450]
509.34ms  9.5120ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [462]
519.07ms  9.5231ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [474]
528.77ms  9.5281ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [486]
539.20ms  2.3161ms                    -               -         -         -         -  4.0000MB  1.6865GB/s  GeForce GTX 980         1         7  [CUDA memcpy DtoH]

Regs: Number of registers used per CUDA thread. This number includes registers used internally by the CUDA driver and/or tools and can be more than what the compiler shows.
SSMem: Static shared memory allocated per CUDA block.
DSMem: Dynamic shared memory allocated per CUDA block.
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 30, average time is 17.515578 msec
Performance= 122.60 GFlop/s, Time= 17.516 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==3832== NVPROF is profiling process 3832, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=30
==3832== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=30
==3832== Profiling result:
==3832== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         32                        achieved_occupancy                        Achieved Occupancy    0.991729    0.993508    0.992592
         32                             sm_efficiency                   Multiprocessor Activity      98.85%      99.73%      99.48%
         32                 warp_execution_efficiency                 Warp Execution Efficiency     100.00%     100.00%     100.00%
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 30, average time is 42.921271 msec
Performance= 50.03 GFlop/s, Time= 42.921 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==4812== NVPROF is profiling process 4812, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=30
==4812== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==4812== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=30
==4812== Profiling result:
==4812== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         32                  eligible_warps_per_cycle           Eligible Warps Per Active Cycle    1.861084    1.867981    1.863541
         32                    dram_read_transactions           Device Memory Read Transactions     4325443     4489836     4411377
         32                      dram_read_throughput             Device Memory Read Throughput  13.579GB/s  14.103GB/s  13.850GB/s
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 30, average time is 39.752759 msec
Performance= 54.02 GFlop/s, Time= 39.753 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==4844== NVPROF is profiling process 4844, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=30
==4844== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==4844== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=30
==4844== Profiling result:
==4844== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         32                   dram_write_transactions          Device Memory Write Transactions      153838      160724      158153
         32                     dram_write_throughput            Device Memory Write Throughput  493.21MB/s  516.16MB/s  507.35MB/s
         32                      l2_read_transactions                      L2 Read Transactions     8388935     8556055     8497945
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 30, average time is 43.246636 msec
Performance= 49.66 GFlop/s, Time= 43.247 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==2516== NVPROF is profiling process 2516, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=30
==2516== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==2516== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=30
==2516== Profiling result:
==2516== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         32                        l2_read_throughput                     L2 Throughput (Reads)  26.278GB/s  26.889GB/s  26.659GB/s
         32                     l2_write_transactions                     L2 Write Transactions      131078      131081      131079
         32                       l2_write_throughput                    L2 Throughput (Writes)  419.91MB/s  422.01MB/s  420.57MB/s
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 30, average time is 13.049158 msec
Performance= 164.57 GFlop/s, Time= 13.049 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==696== NVPROF is profiling process 696, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=30
==696== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=30
==696== Profiling result:
==696== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         32                  shared_load_transactions                  Shared Load Transactions    50331648    50331648    50331648
         32                    shared_load_throughput             Shared Memory Load Throughput  627.84GB/s  633.99GB/s  631.85GB/s
         32                 shared_store_transactions                 Shared Store Transactions     2097152     2097152     2097152
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 30, average time is 16.217554 msec
Performance= 132.42 GFlop/s, Time= 16.218 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==3672== NVPROF is profiling process 3672, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=30
==3672== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=30
==3672== Profiling result:
==3672== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         32                   shared_store_throughput            Shared Memory Store Throughput  26.265GB/s  26.414GB/s  26.337GB/s
         32                         branch_efficiency                         Branch Efficiency     100.00%     100.00%     100.00%
         32                               cf_executed        Executed Control-Flow Instructions     1114112     1114112     1114112
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 30, average time is 432.324309 msec
Performance= 4.97 GFlop/s, Time= 432.324 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==2516== NVPROF is profiling process 2516, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=30
==2516== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==2516== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=30
==2516== Profiling result:
==2516== Metric result:
Invocations                               Metric Name                            Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         32                                 cf_issued              Issued Control-Flow Instructions     1114112     1114112     1114112
         32                             flop_count_sp   Floating Point Operations(Single Precision)  2147483648  2147483648  2147483648
         32                        flop_sp_efficiency                  FLOP Efficiency(Peak Single)      13.54%      13.67%      13.63%
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 30, average time is 61.566991 msec
Performance= 34.88 GFlop/s, Time= 61.567 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==5064== NVPROF is profiling process 5064, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=30
==5064== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==5064== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=30
==5064== Profiling result:
==5064== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         32                            gld_throughput                    Global Load Throughput  26.293GB/s  26.377GB/s  26.332GB/s
         32                          gld_transactions                  Global Load Transactions    16777216    16777216    16777216
         32                            gst_throughput                   Global Store Throughput  420.68MB/s  422.04MB/s  420.57MB/s
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 30, average time is 16.605449 msec
Performance= 129.32 GFlop/s, Time= 16.605 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==3672== NVPROF is profiling process 3672, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=30
==3672== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=30
==3672== Profiling result:
==3672== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         32                          gst_transactions                 Global Store Transactions      131072      131072      131072
         32                               inst_issued                       Instructions Issued    97850402    97850808    97850590
         32                             inst_per_warp                     Instructions per warp  2.9860e+03  2.9860e+03  2.9860e+03
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 30, average time is 13.709432 msec
Performance= 156.64 GFlop/s, Time= 13.709 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==3992== NVPROF is profiling process 3992, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=30
==3992== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=30
==3992== Profiling result:
==3992== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         32                                       ipc                              Executed IPC    1.595117    1.600229    1.597862
