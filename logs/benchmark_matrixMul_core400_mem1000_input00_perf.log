"arg:-wA=1024 -hA=1024 -wB=1024 -hB=1024" 
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
Adjust Iters to 1055 for meeting time requirement 10 secs.
iterated 1055, average time is 9.485534 msec
Performance= 226.40 GFlop/s, Time= 9.486 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 9.520800 msec
Performance= 225.56 GFlop/s, Time= 9.521 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==28700== NVPROF is profiling process 28700, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==28700== Warning: Unified Memory Profiling is not supported on the current configuration because a pair of devices without peer-to-peer support is detected on this multi-GPU setup. When peer mappings are not available, system falls back to using zero-copy memory. It can cause kernels, which access unified memory, to run slower. More details can be found at: http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#um-managed-memory
==28700== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==28700== Profiling result:
Time(%)      Time     Calls       Avg       Min       Max  Name
 98.88%  491.02ms        52  9.4428ms  9.4253ms  9.4555ms  void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
  0.65%  3.2433ms         2  1.6217ms  1.5823ms  1.6610ms  [CUDA memcpy HtoD]
  0.46%  2.2975ms         1  2.2975ms  2.2975ms  2.2975ms  [CUDA memcpy DtoH]

==28700== API calls:
Time(%)      Time     Calls       Avg       Min       Max  Name
 64.00%  485.45ms        51  9.5186ms  9.4899ms  9.5899ms  cudaThreadSynchronize
 25.12%  190.52ms         3  63.506ms  1.1069ms  188.29ms  cudaMalloc
  7.69%  58.329ms         1  58.329ms  58.329ms  58.329ms  cudaDeviceReset
  1.35%  10.212ms         3  3.4039ms  6.8220us  10.187ms  cudaDeviceSynchronize
  0.79%  6.0003ms         3  2.0001ms  1.2576ms  2.7923ms  cudaMemcpy
  0.42%  3.1934ms        51  62.616us  34.112us  208.65us  cudaEventSynchronize
  0.14%  1.0765ms       182  5.9140us       0ns  317.24us  cuDeviceGetAttribute
  0.12%  916.47us        52  17.624us  15.066us  53.726us  cudaLaunch
  0.10%  763.82us       102  7.4880us  5.1160us  16.488us  cudaEventRecord
  0.08%  605.48us         1  605.48us  605.48us  605.48us  cudaGetDeviceProperties
  0.06%  468.18us         3  156.06us  119.39us  182.78us  cudaFree
  0.05%  408.21us        51  8.0040us  7.6750us  8.8120us  cudaEventElapsedTime
  0.03%  262.09us       260  1.0080us       0ns  11.371us  cudaSetupArgument
  0.02%  147.82us         2  73.908us  69.076us  78.741us  cuDeviceGetName
  0.01%  112.29us        52  2.1590us     284ns  11.655us  cudaConfigureCall
  0.00%  13.077us         1  13.077us  13.077us  13.077us  cudaSetDevice
  0.00%  11.371us         2  5.6850us  5.4010us  5.9700us  cuDeviceTotalMem
  0.00%  7.1060us         2  3.5530us  1.1370us  5.9690us  cudaEventCreate
  0.00%  2.8420us         3     947ns     284ns  2.2740us  cuDeviceGetCount
  0.00%  2.5580us         1  2.5580us  2.5580us  2.5580us  cudaGetDevice
  0.00%  1.9890us         6     331ns       0ns     569ns  cuDeviceGet
