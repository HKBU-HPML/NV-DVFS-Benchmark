"arg:-wA=1024 -hA=1024 -wB=1024 -hB=1024" 
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
Adjust Iters to 1829 for meeting time requirement 10 secs.
iterated 1829, average time is 5.488673 msec
Performance= 391.26 GFlop/s, Time= 5.489 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 5.485917 msec
Performance= 391.45 GFlop/s, Time= 5.486 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==80376== NVPROF is profiling process 80376, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==80376== Warning: Unified Memory Profiling is not supported on the current configuration because a pair of devices without peer-to-peer support is detected on this multi-GPU setup. When peer mappings are not available, system falls back to using zero-copy memory. It can cause kernels, which access unified memory, to run slower. More details can be found at: http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#um-managed-memory
==80376== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==80376== Profiling result:
Time(%)      Time     Calls       Avg       Min       Max  Name
 98.16%  281.46ms        52  5.4128ms  5.3763ms  5.4593ms  void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
  1.13%  3.2340ms         2  1.6170ms  1.5727ms  1.6613ms  [CUDA memcpy HtoD]
  0.72%  2.0542ms         1  2.0542ms  2.0542ms  2.0542ms  [CUDA memcpy DtoH]

==80376== API calls:
Time(%)      Time     Calls       Avg       Min       Max  Name
 50.08%  279.77ms        51  5.4856ms  5.4366ms  5.5338ms  cudaThreadSynchronize
 34.09%  190.44ms         3  63.481ms  1.0879ms  188.27ms  cudaMalloc
 12.30%  68.720ms         1  68.720ms  68.720ms  68.720ms  cudaDeviceReset
  1.11%  6.2086ms         3  2.0695ms  6.2540us  6.1850ms  cudaDeviceSynchronize
  1.01%  5.6395ms         3  1.8798ms  1.2357ms  2.4694ms  cudaMemcpy
  0.55%  3.0757ms        51  60.308us  28.426us  125.65us  cudaEventSynchronize
  0.19%  1.0811ms       182  5.9390us       0ns  304.45us  cuDeviceGetAttribute
  0.16%  877.81us        52  16.880us  14.782us  55.147us  cudaLaunch
  0.14%  801.63us       102  7.8590us  5.1170us  17.340us  cudaEventRecord
  0.11%  629.93us         1  629.93us  629.93us  629.93us  cudaGetDeviceProperties
  0.08%  468.18us         3  156.06us  119.11us  185.34us  cudaFree
  0.08%  420.99us        51  8.2540us  7.3910us  9.9490us  cudaEventElapsedTime
  0.03%  187.04us       260     719ns       0ns  11.939us  cudaSetupArgument
  0.03%  148.10us         2  74.051us  69.645us  78.457us  cuDeviceGetName
  0.02%  99.491us        52  1.9130us     284ns  11.655us  cudaConfigureCall
  0.00%  12.792us         1  12.792us  12.792us  12.792us  cudaSetDevice
  0.00%  11.370us         2  5.6850us  5.4010us  5.9690us  cuDeviceTotalMem
  0.00%  7.1060us         2  3.5530us  1.1370us  5.9690us  cudaEventCreate
  0.00%  3.4110us         3  1.1370us     284ns  2.5580us  cuDeviceGetCount
  0.00%  2.5580us         1  2.5580us  2.5580us  2.5580us  cudaGetDevice
  0.00%  1.7060us         6     284ns       0ns     569ns  cuDeviceGet
