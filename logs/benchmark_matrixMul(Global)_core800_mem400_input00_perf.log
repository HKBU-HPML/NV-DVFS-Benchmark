"arg:-wA=1024 -hA=1024 -wB=1024 -hB=1024" 
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
Adjust Iters to 1442 for meeting time requirement 10 secs.
iterated 1442, average time is 6.967586 msec
Performance= 308.21 GFlop/s, Time= 6.968 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 17.452608 msec.
GPU total   time: 872.630404 ms
GPU average time: 17.452608 ms
Performance= 123.05 GFlop/s, Time= 17.453 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==57844== NVPROF is profiling process 57844, command: applications/matrixMul(Global) -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==57844== Warning: Unified Memory Profiling is not supported on the current configuration because a pair of devices without peer-to-peer support is detected on this multi-GPU setup. When peer mappings are not available, system falls back to using zero-copy memory. It can cause kernels, which access unified memory, to run slower. More details can be found at: http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#um-managed-memory
==57844== Profiling application: applications/matrixMul(Global) -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==57844== Profiling result:
Time(%)      Time     Calls       Avg       Min       Max  Name
 99.38%  902.67ms        52  17.359ms  17.335ms  17.404ms  void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
  0.36%  3.2339ms         2  1.6170ms  1.5700ms  1.6640ms  [CUDA memcpy HtoD]
  0.26%  2.3740ms         1  2.3740ms  2.3740ms  2.3740ms  [CUDA memcpy DtoH]

==57844== API calls:
Time(%)      Time     Calls       Avg       Min       Max  Name
 75.37%  889.83ms        51  17.448ms  17.384ms  17.492ms  cudaThreadSynchronize
 16.97%  200.39ms         3  66.795ms  1.0870ms  198.20ms  cudaMalloc
  4.82%  56.950ms         1  56.950ms  56.950ms  56.950ms  cudaDeviceReset
  1.54%  18.158ms         3  6.0527ms  7.3910us  18.133ms  cudaDeviceSynchronize
  0.53%  6.2984ms         3  2.0995ms  1.2368ms  3.1278ms  cudaMemcpy
  0.32%  3.8245ms        51  74.990us  34.111us  166.30us  cudaEventSynchronize
  0.11%  1.3520ms       182  7.4280us       0ns  382.34us  cuDeviceGetAttribute
  0.08%  983.84us        52  18.919us  15.350us  54.010us  cudaLaunch
  0.07%  854.79us       102  8.3800us  4.8330us  26.152us  cudaEventRecord
  0.05%  559.72us         1  559.72us  559.72us  559.72us  cudaGetDeviceProperties
  0.04%  511.68us         3  170.56us  144.12us  185.62us  cudaFree
  0.04%  476.14us        51  9.3360us  7.9590us  10.802us  cudaEventElapsedTime
  0.02%  281.99us         2  141.00us  91.818us  190.17us  cuDeviceGetName
  0.01%  99.492us       260     382ns       0ns  11.655us  cudaSetupArgument
  0.00%  34.396us         1  34.396us  34.396us  34.396us  cudaSetDevice
  0.00%  28.711us        52     552ns     284ns  4.5490us  cudaConfigureCall
  0.00%  11.655us         2  5.8270us  5.6850us  5.9700us  cuDeviceTotalMem
  0.00%  7.3910us         2  3.6950us  1.1370us  6.2540us  cudaEventCreate
  0.00%  3.6960us         3  1.2320us     285ns  2.8430us  cuDeviceGetCount
  0.00%  3.1270us         1  3.1270us  3.1270us  3.1270us  cudaGetDevice
  0.00%  1.9910us         6     331ns       0ns     569ns  cuDeviceGet
