"arg:-wA=1024 -hA=1024 -wB=1024 -hB=1024" 
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
Adjust Iters to 1532 for meeting time requirement 10 secs.
iterated 1532, average time is 6.557964 msec
Performance= 327.46 GFlop/s, Time= 6.558 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 20.382345 msec.
GPU total   time: 1019.117250 ms
GPU average time: 20.382345 ms
Performance= 105.36 GFlop/s, Time= 20.382 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==34560== NVPROF is profiling process 34560, command: applications/matrixMul(Global) -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==34560== Warning: Unified Memory Profiling is not supported on the current configuration because a pair of devices without peer-to-peer support is detected on this multi-GPU setup. When peer mappings are not available, system falls back to using zero-copy memory. It can cause kernels, which access unified memory, to run slower. More details can be found at: http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#um-managed-memory
==34560== Profiling application: applications/matrixMul(Global) -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==34560== Profiling result:
Time(%)      Time     Calls       Avg       Min       Max  Name
 99.54%  1.05464s        52  20.281ms  20.222ms  20.505ms  void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
  0.31%  3.2549ms         2  1.6275ms  1.5739ms  1.6810ms  [CUDA memcpy HtoD]
  0.15%  1.6380ms         1  1.6380ms  1.6380ms  1.6380ms  [CUDA memcpy DtoH]

==34560== API calls:
Time(%)      Time     Calls       Avg       Min       Max  Name
 78.18%  1.03919s        51  20.376ms  20.318ms  20.596ms  cudaThreadSynchronize
 14.16%  188.17ms         3  62.723ms  1.1081ms  185.95ms  cudaMalloc
  5.01%  66.644ms         1  66.644ms  66.644ms  66.644ms  cudaDeviceReset
  1.59%  21.076ms         3  7.0254ms  7.6750us  21.061ms  cudaDeviceSynchronize
  0.39%  5.2211ms         3  1.7404ms  1.2587ms  2.0200ms  cudaMemcpy
  0.31%  4.1707ms        51  81.778us  51.736us  167.15us  cudaEventSynchronize
  0.07%  986.11us        52  18.963us  16.203us  57.137us  cudaLaunch
  0.07%  923.58us       182  5.0740us       0ns  270.33us  cuDeviceGetAttribute
  0.07%  869.85us       102  8.5270us  5.6860us  25.584us  cudaEventRecord
  0.04%  593.83us         1  593.83us  593.83us  593.83us  cudaGetDeviceProperties
  0.04%  518.50us         3  172.83us  141.85us  194.44us  cudaFree
  0.04%  493.77us        51  9.6810us  8.8120us  10.802us  cudaEventElapsedTime
  0.01%  159.19us         2  79.594us  68.224us  90.965us  cuDeviceGetName
  0.00%  56.857us       260     218ns       0ns  1.1370us  cudaSetupArgument
  0.00%  50.599us         1  50.599us  50.599us  50.599us  cudaSetDevice
  0.00%  26.433us        52     508ns     284ns  3.9790us  cudaConfigureCall
  0.00%  11.371us         2  5.6850us  5.6850us  5.6860us  cuDeviceTotalMem
  0.00%  6.8220us         2  3.4110us  1.1370us  5.6850us  cudaEventCreate
  0.00%  3.4120us         3  1.1370us     284ns  2.8430us  cuDeviceGetCount
  0.00%  2.8430us         1  2.8430us  2.8430us  2.8430us  cudaGetDevice
  0.00%  1.7050us         6     284ns     284ns     285ns  cuDeviceGet
