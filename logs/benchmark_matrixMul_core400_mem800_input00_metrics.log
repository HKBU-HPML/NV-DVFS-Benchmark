[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 17.788987 msec
Performance= 120.72 GFlop/s, Time= 17.789 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==8152== NVPROF is profiling process 8152, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==8152== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==8152== Profiling result:
==8152== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (1)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         52                        achieved_occupancy                        Achieved Occupancy    0.990699    0.993964    0.992619
         52                             sm_efficiency                   Multiprocessor Activity      98.58%      99.72%      98.96%
         52                 warp_execution_efficiency                 Warp Execution Efficiency     100.00%     100.00%     100.00%
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 41.968776 msec
Performance= 51.17 GFlop/s, Time= 41.969 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==6824== NVPROF is profiling process 6824, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==6824== Some kernel(s) will be replayed on device 1 in order to collect all events/metrics.
==6824== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==6824== Profiling result:
==6824== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (1)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         52                  eligible_warps_per_cycle           Eligible Warps Per Active Cycle    1.867791    1.874372    1.870926
         52                    dram_read_transactions           Device Memory Read Transactions     4325016     4330779     4326120
         52                      dram_read_throughput             Device Memory Read Throughput  13.579GB/s  13.657GB/s  13.609GB/s
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 39.274772 msec
Performance= 54.68 GFlop/s, Time= 39.275 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==11092== NVPROF is profiling process 11092, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==11092== Some kernel(s) will be replayed on device 1 in order to collect all events/metrics.
==11092== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==11092== Profiling result:
==11092== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (1)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         52                   dram_write_transactions          Device Memory Write Transactions      154590      159980      159521
         52                     dram_write_throughput            Device Memory Write Throughput  496.85MB/s  515.55MB/s  513.08MB/s
         52                      l2_read_transactions                      L2 Read Transactions     8388679     8389007     8388741
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 43.271491 msec
Performance= 49.63 GFlop/s, Time= 43.271 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==6200== NVPROF is profiling process 6200, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==6200== Some kernel(s) will be replayed on device 1 in order to collect all events/metrics.
==6200== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==6200== Profiling result:
==6200== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (1)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         52                        l2_read_throughput                     L2 Throughput (Reads)  26.322GB/s  26.507GB/s  26.389GB/s
         52                     l2_write_transactions                     L2 Write Transactions      131078      131106      131078
         52                       l2_write_throughput                    L2 Throughput (Writes)  421.16MB/s  424.13MB/s  421.52MB/s
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 12.744526 msec
Performance= 168.50 GFlop/s, Time= 12.745 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==4688== NVPROF is profiling process 4688, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==4688== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==4688== Profiling result:
==4688== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (1)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         52                  shared_load_transactions                  Shared Load Transactions    50331648    50331648    50331648
         52                    shared_load_throughput             Shared Memory Load Throughput  631.13GB/s  637.54GB/s  633.22GB/s
         52                 shared_store_transactions                 Shared Store Transactions     2097152     2097152     2097152
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 16.271663 msec
Performance= 131.98 GFlop/s, Time= 16.272 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==7284== NVPROF is profiling process 7284, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==7284== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==7284== Profiling result:
==7284== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (1)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         52                   shared_store_throughput            Shared Memory Store Throughput  26.306GB/s  26.590GB/s  26.398GB/s
         52                         branch_efficiency                         Branch Efficiency     100.00%     100.00%     100.00%
         52                               cf_executed        Executed Control-Flow Instructions     1114112     1114112     1114112
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 424.421221 msec
Performance= 5.06 GFlop/s, Time= 424.421 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==9104== NVPROF is profiling process 9104, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==9104== Some kernel(s) will be replayed on device 1 in order to collect all events/metrics.
==9104== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==9104== Profiling result:
==9104== Metric result:
Invocations                               Metric Name                            Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (1)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         52                                 cf_issued              Issued Control-Flow Instructions     1114112     1114112     1114112
         52                             flop_count_sp   Floating Point Operations(Single Precision)  2147483648  2147483648  2147483648
         52                        flop_sp_efficiency                  FLOP Efficiency(Peak Single)      13.62%      13.77%      13.67%
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 63.092549 msec
Performance= 34.04 GFlop/s, Time= 63.093 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==9612== NVPROF is profiling process 9612, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==9612== Some kernel(s) will be replayed on device 1 in order to collect all events/metrics.
==9612== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==9612== Profiling result:
==9612== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (1)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         52                            gld_throughput                    Global Load Throughput  26.336GB/s  26.529GB/s  26.396GB/s
         52                          gld_transactions                  Global Load Transactions    16777216    16777216    16777216
         52                            gst_throughput                   Global Store Throughput  421.38MB/s  424.46MB/s  421.52MB/s
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 16.787627 msec
Performance= 127.92 GFlop/s, Time= 16.788 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==11280== NVPROF is profiling process 11280, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==11280== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==11280== Profiling result:
==11280== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (1)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         52                          gst_transactions                 Global Store Transactions      131072      131072      131072
         52                               inst_issued                       Instructions Issued    97850258    97850825    97850562
         52                             inst_per_warp                     Instructions per warp  2.9860e+03  2.9860e+03  2.9860e+03
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 13.601367 msec
Performance= 157.89 GFlop/s, Time= 13.601 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==4440== NVPROF is profiling process 4440, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==4440== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==4440== Profiling result:
==4440== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (1)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         52                                       ipc                              Executed IPC    1.608103    1.613197    1.610785
