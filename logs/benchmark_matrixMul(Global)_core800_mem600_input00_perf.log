"arg:-wA=1024 -hA=1024 -wB=1024 -hB=1024" 
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
Adjust Iters to 1830 for meeting time requirement 10 secs.
iterated 1830, average time is 5.487717 msec
Performance= 391.33 GFlop/s, Time= 5.488 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 15.993905 msec.
GPU total   time: 799.695263 ms
GPU average time: 15.993905 ms
Performance= 134.27 GFlop/s, Time= 15.994 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==78976== NVPROF is profiling process 78976, command: applications/matrixMul(Global) -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==78976== Warning: Unified Memory Profiling is not supported on the current configuration because a pair of devices without peer-to-peer support is detected on this multi-GPU setup. When peer mappings are not available, system falls back to using zero-copy memory. It can cause kernels, which access unified memory, to run slower. More details can be found at: http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#um-managed-memory
==78976== Profiling application: applications/matrixMul(Global) -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==78976== Profiling result:
Time(%)      Time     Calls       Avg       Min       Max  Name
 99.41%  826.64ms        52  15.897ms  15.870ms  15.917ms  void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
  0.39%  3.2499ms         2  1.6249ms  1.5875ms  1.6624ms  [CUDA memcpy HtoD]
  0.20%  1.6572ms         1  1.6572ms  1.6572ms  1.6572ms  [CUDA memcpy DtoH]

==78976== API calls:
Time(%)      Time     Calls       Avg       Min       Max  Name
 74.95%  815.50ms        51  15.990ms  15.955ms  16.020ms  cudaThreadSynchronize
 17.08%  185.88ms         3  61.961ms  1.0936ms  183.69ms  cudaMalloc
  5.13%  55.806ms         1  55.806ms  55.806ms  55.806ms  cudaDeviceReset
  1.53%  16.664ms         3  5.5548ms  7.1060us  16.650ms  cudaDeviceSynchronize
  0.49%  5.3297ms         3  1.7766ms  1.2528ms  2.1300ms  cudaMemcpy
  0.36%  3.9382ms        51  77.219us  56.000us  142.70us  cudaEventSynchronize
  0.10%  1.0990ms       182  6.0380us       0ns  309.56us  cuDeviceGetAttribute
  0.09%  959.96us        52  18.460us  15.634us  55.716us  cudaLaunch
  0.08%  860.75us       102  8.4380us  5.6850us  27.858us  cudaEventRecord
  0.06%  626.52us         1  626.52us  626.52us  626.52us  cudaGetDeviceProperties
  0.06%  601.79us         3  200.60us  185.91us  212.63us  cudaFree
  0.04%  483.53us        51  9.4810us  7.9590us  10.802us  cudaEventElapsedTime
  0.02%  167.15us         2  83.574us  69.077us  98.071us  cuDeviceGetName
  0.01%  102.62us       260     394ns       0ns  11.655us  cudaSetupArgument
  0.00%  29.566us        52     568ns     284ns  4.2640us  cudaConfigureCall
  0.00%  14.498us         1  14.498us  14.498us  14.498us  cudaSetDevice
  0.00%  11.939us         2  5.9690us  5.6860us  6.2530us  cuDeviceTotalMem
  0.00%  7.9590us         2  3.9790us  1.1370us  6.8220us  cudaEventCreate
  0.00%  3.4120us         6     568ns       0ns  1.1370us  cuDeviceGet
  0.00%  3.1260us         3  1.0420us     284ns  2.2740us  cuDeviceGetCount
  0.00%  2.5590us         1  2.5590us  2.5590us  2.5590us  cudaGetDevice
