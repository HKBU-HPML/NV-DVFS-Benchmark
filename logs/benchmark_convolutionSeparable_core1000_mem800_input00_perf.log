"arg:" 
[applications\convolutionSeparable] - Starting...
gpuDeviceInit() CUDA Device [1]: "GeForce GTX 980
Image Width x Height = 3072 x 3072

Allocating and initializing host arrays...
Allocating and initializing CUDA arrays...
Running GPU convolution (100 identical iterations)...

Adjust Iters to 2773 for meeting time requirement 10 secs.
iterated 2773, average time is 3.629126 msec.

Reading back GPU results...

Checking the results...
 ...running convolutionRowCPU()
 ...running convolutionColumnCPU()
 ...comparing the results
 ...Relative L2 norm: 0.000000E+000

Shutting down...
Test passed
[applications/convolutionSeparable] - Starting...
gpuDeviceInit() CUDA Device [1]: "GeForce GTX 980
Image Width x Height = 3072 x 3072

Allocating and initializing host arrays...
Allocating and initializing CUDA arrays...
Running GPU convolution (50 identical iterations)...

iterated 50, average time is 3.626038 msec.

Reading back GPU results...

Checking the results...
 ...running convolutionRowCPU()
 ...running convolutionColumnCPU()
 ...comparing the results
 ...Relative L2 norm: 0.000000E+000

Shutting down...
Test passed
==17760== NVPROF is profiling process 17760, command: applications/convolutionSeparable -device=1 -iters=50
==17760== Warning: Unified Memory Profiling is not supported on the current configuration because a pair of devices without peer-to-peer support is detected on this multi-GPU setup. When peer mappings are not available, system falls back to using zero-copy memory. It can cause kernels, which access unified memory, to run slower. More details can be found at: http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#um-managed-memory
==17760== Profiling application: applications/convolutionSeparable -device=1 -iters=50
==17760== Profiling result:
Time(%)      Time     Calls       Avg       Min       Max  Name
 43.64%  93.663ms        51  1.8365ms  1.8302ms  1.8416ms  convolutionColumnsKernel(float*, float*, int, int, int)
 40.74%  87.439ms        51  1.7145ms  1.7114ms  1.7209ms  convolutionRowsKernel(float*, float*, int, int, int)
  8.09%  17.355ms         1  17.355ms  17.355ms  17.355ms  [CUDA memcpy DtoH]
  7.52%  16.146ms         2  8.0728ms  2.4960us  16.143ms  [CUDA memcpy HtoD]

==17760== API calls:
Time(%)      Time     Calls       Avg       Min       Max  Name
 42.60%  221.23ms         3  73.742ms  6.9656ms  207.17ms  cudaMalloc
 35.79%  185.88ms        51  3.6447ms  3.6016ms  4.3751ms  cudaThreadSynchronize
 13.31%  69.112ms         1  69.112ms  69.112ms  69.112ms  cudaDeviceReset
  6.43%  33.398ms         2  16.699ms  15.622ms  17.776ms  cudaMemcpy
  0.56%  2.9293ms        51  57.438us  29.563us  69.361us  cudaEventSynchronize
  0.33%  1.7113ms         3  570.42us  497.75us  668.59us  cudaFree
  0.31%  1.6348ms       102  16.027us  13.076us  58.842us  cudaLaunch
  0.19%  974.18us       182  5.3520us       0ns  291.94us  cuDeviceGetAttribute
  0.15%  758.70us       102  7.4380us  5.1160us  19.614us  cudaEventRecord
  0.12%  603.21us         1  603.21us  603.21us  603.21us  cudaGetDeviceProperties
  0.08%  428.39us        51  8.3990us  7.6750us  9.3810us  cudaEventElapsedTime
  0.05%  246.75us       510     483ns       0ns  11.655us  cudaSetupArgument
  0.03%  179.94us         2  89.970us  69.077us  110.86us  cuDeviceGetName
  0.02%  101.77us       102     997ns       0ns  11.939us  cudaConfigureCall
  0.01%  31.553us         1  31.553us  31.553us  31.553us  cudaMemcpyToSymbol
  0.01%  27.294us       102     267ns       0ns     285ns  cudaGetLastError
  0.00%  25.016us         2  12.508us  6.8230us  18.193us  cudaDeviceSynchronize
  0.00%  15.919us         2  7.9590us  1.4210us  14.498us  cudaEventCreate
  0.00%  12.508us         2  6.2540us  5.6860us  6.8220us  cuDeviceTotalMem
  0.00%  11.371us         1  11.371us  11.371us  11.371us  cudaSetDevice
  0.00%  3.4120us         3  1.1370us     284ns  2.5590us  cuDeviceGetCount
  0.00%  3.1260us         6     521ns     284ns  1.1370us  cuDeviceGet
  0.00%  1.1370us         1  1.1370us  1.1370us  1.1370us  cudaGetDeviceCount
