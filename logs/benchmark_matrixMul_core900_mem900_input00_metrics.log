[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 15, average time is 4.604171 msec
Performance= 466.42 GFlop/s, Time= 4.604 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==13620== NVPROF is profiling process 13620, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==13620== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==13620== Profiling result:
   Start  Duration            Grid Size      Block Size     Regs*    SSMem*    DSMem*      Size  Throughput           Device   Context    Stream  Name
204.83ms  1.5178ms                    -               -         -         -         -  4.0000MB  2.5736GB/s  GeForce GTX 980         1         7  [CUDA memcpy HtoD]
206.68ms  1.5028ms                    -               -         -         -         -  4.0000MB  2.5992GB/s  GeForce GTX 980         1         7  [CUDA memcpy HtoD]
208.19ms  4.5179ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [114]
212.82ms  4.5168ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [125]
217.53ms  4.5097ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [138]
222.37ms  4.5230ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [150]
227.06ms  4.5111ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [162]
231.75ms  4.5106ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [174]
236.44ms  4.5083ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [186]
241.14ms  4.5199ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [198]
245.84ms  4.5340ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [210]
250.55ms  4.5247ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [222]
255.26ms  4.5120ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [234]
259.96ms  4.5338ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [246]
264.67ms  4.5156ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [258]
269.37ms  4.5192ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [270]
274.06ms  4.5342ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [282]
278.76ms  4.5155ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [294]
283.44ms  4.5151ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [306]
288.21ms  2.4282ms                    -               -         -         -         -  4.0000MB  1.6087GB/s  GeForce GTX 980         1         7  [CUDA memcpy DtoH]

Regs: Number of registers used per CUDA thread. This number includes registers used internally by the CUDA driver and/or tools and can be more than what the compiler shows.
SSMem: Static shared memory allocated per CUDA block.
DSMem: Dynamic shared memory allocated per CUDA block.
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 15, average time is 11.222206 msec
Performance= 191.36 GFlop/s, Time= 11.222 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==13696== NVPROF is profiling process 13696, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==13696== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==13696== Profiling result:
==13696== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         17                        achieved_occupancy                        Achieved Occupancy    0.994011    0.994717    0.994372
         17                             sm_efficiency                   Multiprocessor Activity      98.67%      99.26%      98.99%
         17                 warp_execution_efficiency                 Warp Execution Efficiency     100.00%     100.00%     100.00%
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 15, average time is 25.456777 msec
Performance= 84.36 GFlop/s, Time= 25.457 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==13760== NVPROF is profiling process 13760, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==13760== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==13760== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==13760== Profiling result:
==13760== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         17                  eligible_warps_per_cycle           Eligible Warps Per Active Cycle    1.794893    1.800424    1.797152
         17                    dram_read_transactions           Device Memory Read Transactions     4325203     4325617     4325381
         17                      dram_read_throughput             Device Memory Read Throughput  28.476GB/s  28.582GB/s  28.520GB/s
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 15, average time is 23.207512 msec
Performance= 92.53 GFlop/s, Time= 23.208 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==13828== NVPROF is profiling process 13828, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==13828== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==13828== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==13828== Profiling result:
==13828== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         17                   dram_write_transactions          Device Memory Write Transactions      154813      160354      159392
         17                     dram_write_throughput            Device Memory Write Throughput  1.0209GB/s  1.0599GB/s  1.0505GB/s
         17                      l2_read_transactions                      L2 Read Transactions     8388679     8390740     8388994
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 15, average time is 27.225353 msec
Performance= 78.88 GFlop/s, Time= 27.225 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==13896== NVPROF is profiling process 13896, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==13896== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==13896== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==13896== Profiling result:
==13896== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         17                        l2_read_throughput                     L2 Throughput (Reads)  55.272GB/s  55.419GB/s  55.351GB/s
         17                     l2_write_transactions                     L2 Write Transactions      131078      131299      131095
         17                       l2_write_throughput                    L2 Throughput (Writes)  884.35MB/s  886.74MB/s  885.01MB/s
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 15, average time is 7.308928 msec
Performance= 293.82 GFlop/s, Time= 7.309 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==13960== NVPROF is profiling process 13960, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==13960== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==13960== Profiling result:
==13960== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         17                  shared_load_transactions                  Shared Load Transactions    50331648    50331648    50331648
         17                    shared_load_throughput             Shared Memory Load Throughput  1324.0GB/s  1332.9GB/s  1328.1GB/s
         17                 shared_store_transactions                 Shared Store Transactions     2097152     2097152     2097152
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 15, average time is 10.102289 msec
Performance= 212.57 GFlop/s, Time= 10.102 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==14028== NVPROF is profiling process 14028, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==14028== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==14028== Profiling result:
==14028== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         17                   shared_store_throughput            Shared Memory Store Throughput  55.241GB/s  55.497GB/s  55.382GB/s
         17                         branch_efficiency                         Branch Efficiency     100.00%     100.00%     100.00%
         17                               cf_executed        Executed Control-Flow Instructions     1114112     1114112     1114112
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 15, average time is 262.702580 msec
Performance= 8.17 GFlop/s, Time= 262.703 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==14100== NVPROF is profiling process 14100, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==14100== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==14100== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==14100== Profiling result:
==14100== Metric result:
Invocations                               Metric Name                            Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         17                                 cf_issued              Issued Control-Flow Instructions     1114112     1114112     1114112
         17                             flop_count_sp   Floating Point Operations(Single Precision)  2147483648  2147483648  2147483648
         17                        flop_sp_efficiency                  FLOP Efficiency(Peak Single)      12.96%      13.03%      13.00%
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 15, average time is 39.911452 msec
Performance= 53.81 GFlop/s, Time= 39.911 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==14164== NVPROF is profiling process 14164, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==14164== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==14164== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==14164== Profiling result:
==14164== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         17                            gld_throughput                    Global Load Throughput  55.237GB/s  55.408GB/s  55.302GB/s
         17                          gld_transactions                  Global Load Transactions    16777216    16777216    16777216
         17                            gst_throughput                   Global Store Throughput  883.79MB/s  886.52MB/s  884.06MB/s
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 15, average time is 10.618159 msec
Performance= 202.25 GFlop/s, Time= 10.618 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==14228== NVPROF is profiling process 14228, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==14228== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==14228== Profiling result:
==14228== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         17                          gst_transactions                 Global Store Transactions      131072      131072      131072
         17                               inst_issued                       Instructions Issued    97850533    97850986    97850750
         17                             inst_per_warp                     Instructions per warp  2.9860e+03  2.9860e+03  2.9860e+03
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 15, average time is 7.929854 msec
Performance= 270.81 GFlop/s, Time= 7.930 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==14292== NVPROF is profiling process 14292, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==14292== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==14292== Profiling result:
==14292== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         17                                       ipc                              Executed IPC    1.529664    1.534798    1.532394
