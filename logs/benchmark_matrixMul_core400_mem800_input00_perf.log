"arg:-wA=1024 -hA=1024 -wB=1024 -hB=1024" 
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
Adjust Iters to 1046 for meeting time requirement 10 secs.
iterated 1046, average time is 9.548538 msec
Performance= 224.90 GFlop/s, Time= 9.549 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 9.587399 msec
Performance= 223.99 GFlop/s, Time= 9.587 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==10552== NVPROF is profiling process 10552, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==10552== Warning: Unified Memory Profiling is not supported on the current configuration because a pair of devices without peer-to-peer support is detected on this multi-GPU setup. When peer mappings are not available, system falls back to using zero-copy memory. It can cause kernels, which access unified memory, to run slower. More details can be found at: http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#um-managed-memory
==10552== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==10552== Profiling result:
Time(%)      Time     Calls       Avg       Min       Max  Name
 98.90%  494.22ms        52  9.5042ms  9.4258ms  9.5406ms  void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
  0.65%  3.2329ms         2  1.6164ms  1.5757ms  1.6572ms  [CUDA memcpy HtoD]
  0.45%  2.2702ms         1  2.2702ms  2.2702ms  2.2702ms  [CUDA memcpy DtoH]

==10552== API calls:
Time(%)      Time     Calls       Avg       Min       Max  Name
 63.51%  488.80ms        51  9.5843ms  9.4959ms  9.6300ms  cudaThreadSynchronize
 25.32%  194.91ms         3  64.970ms  1.0944ms  192.70ms  cudaMalloc
  7.97%  61.324ms         1  61.324ms  61.324ms  61.324ms  cudaDeviceReset
  1.33%  10.261ms         3  3.4203ms  17.056us  10.225ms  cudaDeviceSynchronize
  0.79%  6.0537ms         3  2.0179ms  1.2414ms  2.8802ms  cudaMemcpy
  0.44%  3.3677ms        51  66.032us  57.421us  210.64us  cudaEventSynchronize
  0.14%  1.0842ms       182  5.9570us       0ns  303.88us  cuDeviceGetAttribute
  0.13%  1.0160ms        52  19.537us  15.350us  121.10us  cudaLaunch
  0.12%  925.00us       102  9.0680us  5.1160us  17.909us  cudaEventRecord
  0.07%  539.25us         3  179.75us  170.56us  184.77us  cudaFree
  0.06%  474.15us         1  474.15us  474.15us  474.15us  cudaGetDeviceProperties
  0.06%  447.14us        51  8.7670us  7.9590us  20.183us  cudaEventElapsedTime
  0.02%  169.14us         2  84.568us  71.066us  98.071us  cuDeviceGetName
  0.02%  158.62us       260     610ns       0ns  11.655us  cudaSetupArgument
  0.01%  71.068us        52  1.3660us     284ns  11.371us  cudaConfigureCall
  0.00%  12.791us         1  12.791us  12.791us  12.791us  cudaSetDevice
  0.00%  11.939us         2  5.9690us  5.4010us  6.5380us  cuDeviceTotalMem
  0.00%  6.2540us         2  3.1270us     853ns  5.4010us  cudaEventCreate
  0.00%  3.4100us         6     568ns       0ns  1.1370us  cuDeviceGet
  0.00%  2.8420us         3     947ns     284ns  1.9900us  cuDeviceGetCount
  0.00%  2.5580us         1  2.5580us  2.5580us  2.5580us  cudaGetDevice
