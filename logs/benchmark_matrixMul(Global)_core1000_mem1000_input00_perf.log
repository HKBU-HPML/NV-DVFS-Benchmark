"arg:-wA=1024 -hA=1024 -wB=1024 -hB=1024" 
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
Adjust Iters to 2380 for meeting time requirement 10 secs.
iterated 2380, average time is 4.178354 msec
Performance= 513.95 GFlop/s, Time= 4.178 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 12.464083 msec.
GPU total   time: 623.204127 ms
GPU average time: 12.464083 ms
Performance= 172.29 GFlop/s, Time= 12.464 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==38128== NVPROF is profiling process 38128, command: applications/matrixMul(Global) -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==38128== Warning: Unified Memory Profiling is not supported on the current configuration because a pair of devices without peer-to-peer support is detected on this multi-GPU setup. When peer mappings are not available, system falls back to using zero-copy memory. It can cause kernels, which access unified memory, to run slower. More details can be found at: http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#um-managed-memory
==38128== Profiling application: applications/matrixMul(Global) -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==38128== Profiling result:
Time(%)      Time     Calls       Avg       Min       Max  Name
 99.21%  643.68ms        52  12.379ms  12.341ms  12.398ms  void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
  0.50%  3.2342ms         2  1.6171ms  1.5722ms  1.6619ms  [CUDA memcpy HtoD]
  0.29%  1.9110ms         1  1.9110ms  1.9110ms  1.9110ms  [CUDA memcpy DtoH]

==38128== API calls:
Time(%)      Time     Calls       Avg       Min       Max  Name
 71.29%  635.48ms        51  12.460ms  12.409ms  12.492ms  cudaThreadSynchronize
 18.76%  167.24ms         3  55.746ms  1.0853ms  165.06ms  cudaMalloc
  6.92%  61.666ms         1  61.666ms  61.666ms  61.666ms  cudaDeviceReset
  1.48%  13.158ms         3  4.3859ms  6.5380us  13.144ms  cudaDeviceSynchronize
  0.63%  5.6236ms         3  1.8745ms  1.2408ms  2.4526ms  cudaMemcpy
  0.40%  3.5215ms        51  69.048us  34.112us  142.42us  cudaEventSynchronize
  0.12%  1.0290ms       182  5.6540us       0ns  281.99us  cuDeviceGetAttribute
  0.10%  929.26us        52  17.870us  14.782us  56.285us  cudaLaunch
  0.10%  847.39us       102  8.3070us  4.8330us  16.772us  cudaEventRecord
  0.06%  578.76us         1  578.76us  578.76us  578.76us  cudaGetDeviceProperties
  0.06%  505.71us         3  168.57us  141.85us  185.91us  cudaFree
  0.05%  456.24us        51  8.9450us  7.9590us  10.518us  cudaEventElapsedTime
  0.02%  157.77us         2  78.883us  68.508us  89.259us  cuDeviceGetName
  0.01%  117.40us       260     451ns       0ns  11.371us  cudaSetupArgument
  0.01%  47.475us        52     912ns     284ns  11.939us  cudaConfigureCall
  0.00%  14.782us         1  14.782us  14.782us  14.782us  cudaSetDevice
  0.00%  11.371us         2  5.6850us  5.6850us  5.6860us  cuDeviceTotalMem
  0.00%  6.5380us         2  3.2690us  1.1370us  5.4010us  cudaEventCreate
  0.00%  3.1280us         3  1.0420us     285ns  2.2740us  cuDeviceGetCount
  0.00%  2.5590us         1  2.5590us  2.5590us  2.5590us  cudaGetDevice
  0.00%  2.2760us         6     379ns       0ns     569ns  cuDeviceGet
