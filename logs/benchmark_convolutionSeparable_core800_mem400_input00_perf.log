"arg:" 
[applications\convolutionSeparable] - Starting...
gpuDeviceInit() CUDA Device [1]: "GeForce GTX 980
Image Width x Height = 3072 x 3072

Allocating and initializing host arrays...
Allocating and initializing CUDA arrays...
Running GPU convolution (100 identical iterations)...

Adjust Iters to 1239 for meeting time requirement 10 secs.
iterated 1239, average time is 7.971165 msec.

Reading back GPU results...

Checking the results...
 ...running convolutionRowCPU()
 ...running convolutionColumnCPU()
 ...comparing the results
 ...Relative L2 norm: 0.000000E+000

Shutting down...
Test passed
[applications/convolutionSeparable] - Starting...
gpuDeviceInit() CUDA Device [1]: "GeForce GTX 980
Image Width x Height = 3072 x 3072

Allocating and initializing host arrays...
Allocating and initializing CUDA arrays...
Running GPU convolution (50 identical iterations)...

iterated 50, average time is 7.975581 msec.

Reading back GPU results...

Checking the results...
 ...running convolutionRowCPU()
 ...running convolutionColumnCPU()
 ...comparing the results
 ...Relative L2 norm: 0.000000E+000

Shutting down...
Test passed
==51132== NVPROF is profiling process 51132, command: applications/convolutionSeparable -device=1 -iters=50
==51132== Warning: Unified Memory Profiling is not supported on the current configuration because a pair of devices without peer-to-peer support is detected on this multi-GPU setup. When peer mappings are not available, system falls back to using zero-copy memory. It can cause kernels, which access unified memory, to run slower. More details can be found at: http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#um-managed-memory
==51132== Profiling application: applications/convolutionSeparable -device=1 -iters=50
==51132== Profiling result:
Time(%)      Time     Calls       Avg       Min       Max  Name
 47.79%  208.23ms        51  4.0830ms  4.0581ms  4.1012ms  convolutionColumnsKernel(float*, float*, int, int, int)
 44.44%  193.62ms        51  3.7965ms  3.7669ms  3.8213ms  convolutionRowsKernel(float*, float*, int, int, int)
  4.03%  17.574ms         1  17.574ms  17.574ms  17.574ms  [CUDA memcpy DtoH]
  3.74%  16.301ms         2  8.1506ms  3.1360us  16.298ms  [CUDA memcpy HtoD]

==51132== API calls:
Time(%)      Time     Calls       Avg       Min       Max  Name
 56.15%  407.83ms        51  7.9967ms  7.9435ms  8.8474ms  cudaThreadSynchronize
 28.42%  206.43ms         3  68.810ms  6.9992ms  192.32ms  cudaMalloc
  9.30%  67.561ms         1  67.561ms  67.561ms  67.561ms  cudaDeviceReset
  4.67%  33.898ms         2  16.949ms  15.894ms  18.004ms  cudaMemcpy
  0.51%  3.6934ms        51  72.420us  59.127us  92.101us  cudaEventSynchronize
  0.26%  1.9014ms         3  633.82us  528.73us  842.56us  cudaFree
  0.23%  1.6712ms       102  16.384us  14.497us  61.116us  cudaLaunch
  0.14%  1.0370ms       182  5.6970us       0ns  278.30us  cuDeviceGetAttribute
  0.12%  847.68us       102  8.3100us  5.6850us  18.478us  cudaEventRecord
  0.08%  577.06us         1  577.06us  577.06us  577.06us  cudaGetDeviceProperties
  0.07%  492.06us        51  9.6480us  9.0960us  19.045us  cudaEventElapsedTime
  0.02%  150.94us         2  75.471us  70.781us  80.162us  cuDeviceGetName
  0.01%  105.17us       510     206ns       0ns  1.4210us  cudaSetupArgument
  0.00%  34.391us       102     337ns       0ns  3.6950us  cudaConfigureCall
  0.00%  30.417us         1  30.417us  30.417us  30.417us  cudaMemcpyToSymbol
  0.00%  30.131us       102     295ns       0ns     569ns  cudaGetLastError
  0.00%  15.350us         2  7.6750us  1.1370us  14.213us  cudaEventCreate
  0.00%  14.213us         2  7.1060us  7.1060us  7.1070us  cudaDeviceSynchronize
  0.00%  11.655us         1  11.655us  11.655us  11.655us  cudaSetDevice
  0.00%  11.370us         2  5.6850us  5.6850us  5.6850us  cuDeviceTotalMem
  0.00%  3.1280us         3  1.0420us     284ns  2.5590us  cuDeviceGetCount
  0.00%  2.2750us         6     379ns       0ns     569ns  cuDeviceGet
  0.00%  1.1370us         1  1.1370us  1.1370us  1.1370us  cudaGetDeviceCount
