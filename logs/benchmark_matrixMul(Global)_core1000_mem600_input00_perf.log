"arg:-wA=1024 -hA=1024 -wB=1024 -hB=1024" 
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
Adjust Iters to 2065 for meeting time requirement 10 secs.
iterated 2065, average time is 4.881171 msec
Performance= 439.95 GFlop/s, Time= 4.881 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 13.506727 msec.
GPU total   time: 675.336352 ms
GPU average time: 13.506727 ms
Performance= 158.99 GFlop/s, Time= 13.507 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==86948== NVPROF is profiling process 86948, command: applications/matrixMul(Global) -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==86948== Warning: Unified Memory Profiling is not supported on the current configuration because a pair of devices without peer-to-peer support is detected on this multi-GPU setup. When peer mappings are not available, system falls back to using zero-copy memory. It can cause kernels, which access unified memory, to run slower. More details can be found at: http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#um-managed-memory
==86948== Profiling application: applications/matrixMul(Global) -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==86948== Profiling result:
Time(%)      Time     Calls       Avg       Min       Max  Name
 99.28%  698.44ms        52  13.431ms  13.412ms  13.460ms  void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
  0.46%  3.2352ms         2  1.6176ms  1.5677ms  1.6675ms  [CUDA memcpy HtoD]
  0.26%  1.8556ms         1  1.8556ms  1.8556ms  1.8556ms  [CUDA memcpy DtoH]

==86948== API calls:
Time(%)      Time     Calls       Avg       Min       Max  Name
 70.95%  688.82ms        51  13.506ms  13.479ms  13.553ms  cudaThreadSynchronize
 19.49%  189.18ms         3  63.059ms  1.0924ms  186.99ms  cudaMalloc
  6.71%  65.159ms         1  65.159ms  65.159ms  65.159ms  cudaDeviceReset
  1.46%  14.221ms         3  4.7404ms  7.6750us  14.197ms  cudaDeviceSynchronize
  0.57%  5.5821ms         3  1.8607ms  1.2354ms  2.3986ms  cudaMemcpy
  0.32%  3.1391ms        51  61.551us  49.462us  115.13us  cudaEventSynchronize
  0.11%  1.0865ms       182  5.9690us       0ns  303.59us  cuDeviceGetAttribute
  0.09%  900.83us        52  17.323us  14.497us  54.579us  cudaLaunch
  0.08%  778.60us       102  7.6330us  4.5480us  16.771us  cudaEventRecord
  0.06%  608.61us         1  608.61us  608.61us  608.61us  cudaGetDeviceProperties
  0.05%  505.42us         3  168.47us  119.96us  222.86us  cudaFree
  0.04%  418.15us        51  8.1990us  7.6750us  10.233us  cudaEventElapsedTime
  0.02%  180.23us         2  90.112us  71.351us  108.87us  cuDeviceGetName
  0.02%  164.02us       260     630ns       0ns  11.655us  cudaSetupArgument
  0.01%  78.745us        52  1.5140us     284ns  11.086us  cudaConfigureCall
  0.00%  14.498us         1  14.498us  14.498us  14.498us  cudaSetDevice
  0.00%  12.508us         2  6.2540us  5.6860us  6.8220us  cuDeviceTotalMem
  0.00%  6.5380us         2  3.2690us     853ns  5.6850us  cudaEventCreate
  0.00%  2.8430us         1  2.8430us  2.8430us  2.8430us  cudaGetDevice
  0.00%  2.8420us         6     473ns       0ns     853ns  cuDeviceGet
  0.00%  2.8420us         3     947ns     284ns  2.2740us  cuDeviceGetCount
