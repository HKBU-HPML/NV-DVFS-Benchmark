"arg:-wA=1024 -hA=1024 -wB=1024 -hB=1024" 
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
Adjust Iters to 1052 for meeting time requirement 10 secs.
iterated 1052, average time is 9.481717 msec
Performance= 226.49 GFlop/s, Time= 9.482 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 30.459731 msec.
GPU total   time: 1522.986526 ms
GPU average time: 30.459731 ms
Performance= 70.50 GFlop/s, Time= 30.460 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==24052== NVPROF is profiling process 24052, command: applications/matrixMul(Global) -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==24052== Warning: Unified Memory Profiling is not supported on the current configuration because a pair of devices without peer-to-peer support is detected on this multi-GPU setup. When peer mappings are not available, system falls back to using zero-copy memory. It can cause kernels, which access unified memory, to run slower. More details can be found at: http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#um-managed-memory
==24052== Profiling application: applications/matrixMul(Global) -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==24052== Profiling result:
Time(%)      Time     Calls       Avg       Min       Max  Name
 99.68%  1.57843s        52  30.354ms  30.293ms  30.412ms  void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
  0.21%  3.2928ms         2  1.6464ms  1.6016ms  1.6913ms  [CUDA memcpy HtoD]
  0.11%  1.7934ms         1  1.7934ms  1.7934ms  1.7934ms  [CUDA memcpy DtoH]

==24052== API calls:
Time(%)      Time     Calls       Avg       Min       Max  Name
 83.99%  1.55277s        51  30.446ms  30.371ms  30.527ms  cudaThreadSynchronize
 10.16%  187.79ms         3  62.596ms  1.1069ms  185.57ms  cudaMalloc
  3.35%  61.947ms         1  61.947ms  61.947ms  61.947ms  cudaDeviceReset
  1.68%  31.151ms         3  10.384ms  7.3900us  31.126ms  cudaDeviceSynchronize
  0.31%  5.6566ms         3  1.8855ms  1.2690ms  2.4000ms  cudaMemcpy
  0.24%  4.4021ms        51  86.316us  58.559us  215.47us  cudaEventSynchronize
  0.07%  1.2272ms       182  6.7420us       0ns  319.80us  cuDeviceGetAttribute
  0.05%  1.0006ms        52  19.242us  15.634us  54.011us  cudaLaunch
  0.05%  853.36us       102  8.3660us  5.1160us  25.299us  cudaEventRecord
  0.03%  605.20us         3  201.73us  187.61us  218.32us  cudaFree
  0.03%  598.66us         1  598.66us  598.66us  598.66us  cudaGetDeviceProperties
  0.03%  483.54us        51  9.4810us  7.9590us  10.802us  cudaEventElapsedTime
  0.01%  174.54us         2  87.269us  73.340us  101.20us  cuDeviceGetName
  0.00%  88.687us       260     341ns       0ns  11.655us  cudaSetupArgument
  0.00%  52.878us        52  1.0160us     284ns  11.655us  cudaConfigureCall
  0.00%  14.782us         1  14.782us  14.782us  14.782us  cudaSetDevice
  0.00%  12.507us         2  6.2530us  5.6850us  6.8220us  cuDeviceTotalMem
  0.00%  8.8120us         2  4.4060us  1.4210us  7.3910us  cudaEventCreate
  0.00%  3.1280us         3  1.0420us     284ns  2.5590us  cuDeviceGetCount
  0.00%  2.5580us         6     426ns       0ns     853ns  cuDeviceGet
  0.00%  2.5580us         1  2.5580us  2.5580us  2.5580us  cudaGetDevice
