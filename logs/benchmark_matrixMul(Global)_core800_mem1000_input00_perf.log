"arg:-wA=1024 -hA=1024 -wB=1024 -hB=1024" 
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
Adjust Iters to 1990 for meeting time requirement 10 secs.
iterated 1990, average time is 5.071137 msec
Performance= 423.47 GFlop/s, Time= 5.071 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 15.411492 msec.
GPU total   time: 770.574590 ms
GPU average time: 15.411492 ms
Performance= 139.34 GFlop/s, Time= 15.411 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==41664== NVPROF is profiling process 41664, command: applications/matrixMul(Global) -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==41664== Warning: Unified Memory Profiling is not supported on the current configuration because a pair of devices without peer-to-peer support is detected on this multi-GPU setup. When peer mappings are not available, system falls back to using zero-copy memory. It can cause kernels, which access unified memory, to run slower. More details can be found at: http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#um-managed-memory
==41664== Profiling application: applications/matrixMul(Global) -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==41664== Profiling result:
Time(%)      Time     Calls       Avg       Min       Max  Name
 99.39%  797.03ms        52  15.328ms  15.305ms  15.354ms  void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
  0.41%  3.2719ms         2  1.6360ms  1.5847ms  1.6873ms  [CUDA memcpy HtoD]
  0.21%  1.6500ms         1  1.6500ms  1.6500ms  1.6500ms  [CUDA memcpy DtoH]

==41664== API calls:
Time(%)      Time     Calls       Avg       Min       Max  Name
 72.85%  785.75ms        51  15.407ms  15.374ms  15.488ms  cudaThreadSynchronize
 18.46%  199.08ms         3  66.360ms  1.3005ms  196.47ms  cudaMalloc
  5.92%  63.882ms         1  63.882ms  63.882ms  63.882ms  cudaDeviceReset
  1.49%  16.114ms         3  5.3715ms  17.624us  16.079ms  cudaDeviceSynchronize
  0.50%  5.3629ms         3  1.7876ms  1.2658ms  2.0965ms  cudaMemcpy
  0.32%  3.4780ms        51  68.195us  39.512us  156.35us  cudaEventSynchronize
  0.10%  1.0549ms       182  5.7960us       0ns  284.55us  cuDeviceGetAttribute
  0.09%  919.59us        52  17.684us  14.781us  53.158us  cudaLaunch
  0.08%  913.34us       102  8.9540us  4.8330us  27.857us  cudaEventRecord
  0.05%  591.55us         1  591.55us  591.55us  591.55us  cudaGetDeviceProperties
  0.05%  531.01us         3  177.00us  121.38us  212.63us  cudaFree
  0.04%  453.12us        51  8.8840us  7.9590us  21.036us  cudaEventElapsedTime
  0.02%  185.91us       260     715ns       0ns  11.371us  cudaSetupArgument
  0.02%  177.67us         2  88.832us  68.792us  108.87us  cuDeviceGetName
  0.01%  59.693us        52  1.1470us     284ns  11.654us  cudaConfigureCall
  0.00%  14.498us         1  14.498us  14.498us  14.498us  cudaSetDevice
  0.00%  12.507us         2  6.2530us  5.6850us  6.8220us  cuDeviceTotalMem
  0.00%  6.8220us         2  3.4110us  1.1370us  5.6850us  cudaEventCreate
  0.00%  3.1280us         3  1.0420us     284ns  2.5590us  cuDeviceGetCount
  0.00%  2.8420us         1  2.8420us  2.8420us  2.8420us  cudaGetDevice
  0.00%  2.2740us         6     379ns       0ns     852ns  cuDeviceGet
