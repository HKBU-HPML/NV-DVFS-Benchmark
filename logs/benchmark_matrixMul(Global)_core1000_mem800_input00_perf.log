"arg:-wA=1024 -hA=1024 -wB=1024 -hB=1024" 
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
Adjust Iters to 2322 for meeting time requirement 10 secs.
iterated 2322, average time is 4.305250 msec
Performance= 498.81 GFlop/s, Time= 4.305 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 12.672586 msec.
GPU total   time: 633.629313 ms
GPU average time: 12.672586 ms
Performance= 169.46 GFlop/s, Time= 12.673 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==22328== NVPROF is profiling process 22328, command: applications/matrixMul(Global) -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==22328== Warning: Unified Memory Profiling is not supported on the current configuration because a pair of devices without peer-to-peer support is detected on this multi-GPU setup. When peer mappings are not available, system falls back to using zero-copy memory. It can cause kernels, which access unified memory, to run slower. More details can be found at: http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#um-managed-memory
==22328== Profiling application: applications/matrixMul(Global) -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==22328== Profiling result:
Time(%)      Time     Calls       Avg       Min       Max  Name
 99.21%  654.38ms        52  12.584ms  12.562ms  12.620ms  void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
  0.49%  3.2377ms         2  1.6188ms  1.5717ms  1.6659ms  [CUDA memcpy HtoD]
  0.30%  1.9535ms         1  1.9535ms  1.9535ms  1.9535ms  [CUDA memcpy DtoH]

==22328== API calls:
Time(%)      Time     Calls       Avg       Min       Max  Name
 70.56%  646.46ms        51  12.676ms  12.646ms  12.714ms  cudaThreadSynchronize
 19.95%  182.79ms         3  60.929ms  1.0848ms  180.61ms  cudaMalloc
  6.48%  59.331ms         1  59.331ms  59.331ms  59.331ms  cudaDeviceReset
  1.46%  13.346ms         3  4.4486ms  7.1070us  13.331ms  cudaDeviceSynchronize
  0.62%  5.7055ms         3  1.9018ms  1.2474ms  2.5174ms  cudaMemcpy
  0.40%  3.6261ms        51  71.099us  44.345us  124.22us  cudaEventSynchronize
  0.14%  1.3028ms       182  7.1580us       0ns  398.25us  cuDeviceGetAttribute
  0.10%  942.05us        52  18.116us  15.350us  55.716us  cudaLaunch
  0.09%  825.78us       102  8.0950us  4.8320us  15.635us  cudaEventRecord
  0.07%  610.32us         1  610.32us  610.32us  610.32us  cudaGetDeviceProperties
  0.06%  531.57us         3  177.19us  146.96us  198.13us  cudaFree
  0.05%  499.74us        51  9.7980us  7.9590us  21.036us  cudaEventElapsedTime
  0.02%  146.40us         2  73.198us  69.645us  76.751us  cuDeviceGetName
  0.01%  58.560us       260     225ns       0ns  1.1370us  cudaSetupArgument
  0.00%  28.710us        52     552ns     284ns  4.8330us  cudaConfigureCall
  0.00%  14.213us         1  14.213us  14.213us  14.213us  cudaSetDevice
  0.00%  11.086us         2  5.5430us  5.4010us  5.6850us  cuDeviceTotalMem
  0.00%  6.8230us         2  3.4110us     853ns  5.9700us  cudaEventCreate
  0.00%  2.8430us         1  2.8430us  2.8430us  2.8430us  cudaGetDevice
  0.00%  2.8420us         6     473ns       0ns  1.1370us  cuDeviceGet
  0.00%  2.5580us         3     852ns       0ns  2.2740us  cuDeviceGetCount
