[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 15, average time is 4.906016 msec
Performance= 437.72 GFlop/s, Time= 4.906 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==14276== NVPROF is profiling process 14276, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==14276== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==14276== Profiling result:
   Start  Duration            Grid Size      Block Size     Regs*    SSMem*    DSMem*      Size  Throughput           Device   Context    Stream  Name
201.06ms  1.4754ms                    -               -         -         -         -  4.0000MB  2.6476GB/s  GeForce GTX 980         1         7  [CUDA memcpy HtoD]
202.89ms  1.5324ms                    -               -         -         -         -  4.0000MB  2.5490GB/s  GeForce GTX 980         1         7  [CUDA memcpy HtoD]
204.43ms  4.8636ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [114]
209.41ms  4.8328ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [125]
214.45ms  4.8152ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [138]
219.45ms  4.8595ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [150]
224.49ms  4.8095ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [162]
229.49ms  4.8220ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [174]
234.50ms  4.8763ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [186]
239.56ms  4.8492ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [198]
244.59ms  4.8096ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [210]
249.58ms  4.8440ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [222]
254.67ms  4.8292ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [234]
259.61ms  4.7815ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [246]
264.57ms  4.8191ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [258]
269.56ms  4.8520ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [270]
274.60ms  4.8549ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [282]
279.64ms  4.8308ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [294]
284.65ms  4.7951ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [306]
289.63ms  2.3192ms                    -               -         -         -         -  4.0000MB  1.6843GB/s  GeForce GTX 980         1         7  [CUDA memcpy DtoH]

Regs: Number of registers used per CUDA thread. This number includes registers used internally by the CUDA driver and/or tools and can be more than what the compiler shows.
SSMem: Static shared memory allocated per CUDA block.
DSMem: Dynamic shared memory allocated per CUDA block.
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 15, average time is 11.442236 msec
Performance= 187.68 GFlop/s, Time= 11.442 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==8824== NVPROF is profiling process 8824, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==8824== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==8824== Profiling result:
==8824== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         17                        achieved_occupancy                        Achieved Occupancy    0.993758    0.995504    0.994851
         17                             sm_efficiency                   Multiprocessor Activity      98.78%      99.24%      98.96%
         17                 warp_execution_efficiency                 Warp Execution Efficiency     100.00%     100.00%     100.00%
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 15, average time is 27.331763 msec
Performance= 78.57 GFlop/s, Time= 27.332 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==13456== NVPROF is profiling process 13456, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==13456== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==13456== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==13456== Profiling result:
==13456== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         17                  eligible_warps_per_cycle           Eligible Warps Per Active Cycle    1.443112    1.468042    1.460971
         17                    dram_read_transactions           Device Memory Read Transactions     4324367     4325443     4324915
         17                      dram_read_throughput             Device Memory Read Throughput  26.494GB/s  26.770GB/s  26.625GB/s
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 15, average time is 24.778972 msec
Performance= 86.67 GFlop/s, Time= 24.779 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==13252== NVPROF is profiling process 13252, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==13252== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==13252== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==13252== Profiling result:
==13252== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         17                   dram_write_transactions          Device Memory Write Transactions      156817      160221      159610
         17                     dram_write_throughput            Device Memory Write Throughput  988.69MB/s  0.9912GB/s  0.9816GB/s
         17                      l2_read_transactions                      L2 Read Transactions     8388679     8389065     8388853
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 15, average time is 28.841784 msec
Performance= 74.46 GFlop/s, Time= 28.842 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==11872== NVPROF is profiling process 11872, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==11872== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==11872== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==11872== Profiling result:
==11872== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         17                        l2_read_throughput                     L2 Throughput (Reads)  51.464GB/s  51.981GB/s  51.681GB/s
         17                     l2_write_transactions                     L2 Write Transactions      131078      131299      131117
         17                       l2_write_throughput                    L2 Throughput (Writes)  823.42MB/s  831.73MB/s  825.88MB/s
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 15, average time is 7.577380 msec
Performance= 283.41 GFlop/s, Time= 7.577 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==14052== NVPROF is profiling process 14052, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==14052== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==14052== Profiling result:
==14052== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         17                  shared_load_transactions                  Shared Load Transactions    50331648    50331648    50331648
         17                    shared_load_throughput             Shared Memory Load Throughput  1234.1GB/s  1254.0GB/s  1242.7GB/s
         17                 shared_store_transactions                 Shared Store Transactions     2097152     2097152     2097152
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 15, average time is 11.051305 msec
Performance= 194.32 GFlop/s, Time= 11.051 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==13328== NVPROF is profiling process 13328, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==13328== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==13328== Profiling result:
==13328== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         17                   shared_store_throughput            Shared Memory Store Throughput  51.515GB/s  52.126GB/s  51.854GB/s
         17                         branch_efficiency                         Branch Efficiency     100.00%     100.00%     100.00%
         17                               cf_executed        Executed Control-Flow Instructions     1114112     1114112     1114112
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 15, average time is 397.003676 msec
Performance= 5.41 GFlop/s, Time= 397.004 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==8824== NVPROF is profiling process 8824, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==8824== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==8824== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==8824== Profiling result:
==8824== Metric result:
Invocations                               Metric Name                            Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         17                                 cf_issued              Issued Control-Flow Instructions     1114112     1114112     1114112
         17                             flop_count_sp   Floating Point Operations(Single Precision)  2147483648  2147483648  2147483648
         17                        flop_sp_efficiency                  FLOP Efficiency(Peak Single)      10.95%      11.11%      11.03%
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 15, average time is 41.356312 msec
Performance= 51.93 GFlop/s, Time= 41.356 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==13804== NVPROF is profiling process 13804, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==13804== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==13804== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==13804== Profiling result:
==13804== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         17                            gld_throughput                    Global Load Throughput  51.421GB/s  52.000GB/s  51.713GB/s
         17                          gld_transactions                  Global Load Transactions    16777216    16777216    16777216
         17                            gst_throughput                   Global Store Throughput  822.73MB/s  832.00MB/s  826.84MB/s
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 15, average time is 11.514325 msec
Performance= 186.51 GFlop/s, Time= 11.514 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==13376== NVPROF is profiling process 13376, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==13376== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==13376== Profiling result:
==13376== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         17                          gst_transactions                 Global Store Transactions      131072      131072      131072
         17                               inst_issued                       Instructions Issued    97850794    97851496    97851151
         17                             inst_per_warp                     Instructions per warp  2.9860e+03  2.9860e+03  2.9860e+03
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 15, average time is 8.311838 msec
Performance= 258.36 GFlop/s, Time= 8.312 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==8824== NVPROF is profiling process 8824, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==8824== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==8824== Profiling result:
==8824== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         17                                       ipc                              Executed IPC    1.292681    1.310593    1.301176
