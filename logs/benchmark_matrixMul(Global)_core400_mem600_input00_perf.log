"arg:-wA=1024 -hA=1024 -wB=1024 -hB=1024" 
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
Adjust Iters to 1037 for meeting time requirement 10 secs.
iterated 1037, average time is 9.662901 msec
Performance= 222.24 GFlop/s, Time= 9.663 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 30.543098 msec.
GPU total   time: 1527.154877 ms
GPU average time: 30.543098 ms
Performance= 70.31 GFlop/s, Time= 30.543 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==61736== NVPROF is profiling process 61736, command: applications/matrixMul(Global) -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==61736== Warning: Unified Memory Profiling is not supported on the current configuration because a pair of devices without peer-to-peer support is detected on this multi-GPU setup. When peer mappings are not available, system falls back to using zero-copy memory. It can cause kernels, which access unified memory, to run slower. More details can be found at: http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#um-managed-memory
==61736== Profiling application: applications/matrixMul(Global) -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==61736== Profiling result:
Time(%)      Time     Calls       Avg       Min       Max  Name
 99.68%  1.58279s        52  30.438ms  30.388ms  30.493ms  void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
  0.20%  3.2424ms         2  1.6212ms  1.5724ms  1.6700ms  [CUDA memcpy HtoD]
  0.12%  1.8983ms         1  1.8983ms  1.8983ms  1.8983ms  [CUDA memcpy DtoH]

==61736== API calls:
Time(%)      Time     Calls       Avg       Min       Max  Name
 83.39%  1.55722s        51  30.534ms  30.487ms  30.602ms  cudaThreadSynchronize
 10.39%  194.07ms         3  64.689ms  1.0916ms  191.88ms  cudaMalloc
  3.74%  69.888ms         1  69.888ms  69.888ms  69.888ms  cudaDeviceReset
  1.67%  31.203ms         3  10.401ms  7.3910us  31.189ms  cudaDeviceSynchronize
  0.30%  5.6847ms         3  1.8949ms  1.2366ms  2.5035ms  cudaMemcpy
  0.24%  4.4359ms        51  86.979us  58.843us  310.13us  cudaEventSynchronize
  0.06%  1.0904ms       182  5.9910us       0ns  314.97us  cuDeviceGetAttribute
  0.05%  986.97us        52  18.980us  15.919us  54.863us  cudaLaunch
  0.05%  860.47us       102  8.4350us  5.4010us  17.909us  cudaEventRecord
  0.03%  635.90us         1  635.90us  635.90us  635.90us  cudaGetDeviceProperties
  0.03%  544.65us         3  181.55us  143.84us  213.48us  cudaFree
  0.03%  502.30us        51  9.8480us  7.6750us  21.036us  cudaEventElapsedTime
  0.01%  157.77us         2  78.883us  67.939us  89.828us  cuDeviceGetName
  0.00%  59.127us       260     227ns       0ns  1.1370us  cudaSetupArgument
  0.00%  29.281us        52     563ns     284ns  4.8320us  cudaConfigureCall
  0.00%  14.213us         1  14.213us  14.213us  14.213us  cudaSetDevice
  0.00%  10.803us         2  5.4010us  5.1170us  5.6860us  cuDeviceTotalMem
  0.00%  8.8120us         2  4.4060us  1.1370us  7.6750us  cudaEventCreate
  0.00%  2.8430us         3     947ns     284ns  2.2740us  cuDeviceGetCount
  0.00%  2.5580us         1  2.5580us  2.5580us  2.5580us  cudaGetDevice
  0.00%  1.9900us         6     331ns       0ns     569ns  cuDeviceGet
