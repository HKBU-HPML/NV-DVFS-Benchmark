[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 15.113855 msec
Performance= 142.09 GFlop/s, Time= 15.114 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==60680== NVPROF is profiling process 60680, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==60680== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==60680== Profiling result:
==60680== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (1)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         52                        achieved_occupancy                        Achieved Occupancy    0.994759    0.996935    0.996008
         52                             sm_efficiency                   Multiprocessor Activity      98.79%      99.40%      99.18%
         52                 warp_execution_efficiency                 Warp Execution Efficiency     100.00%     100.00%     100.00%
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 35.296443 msec
Performance= 60.84 GFlop/s, Time= 35.296 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==64224== NVPROF is profiling process 64224, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==64224== Some kernel(s) will be replayed on device 1 in order to collect all events/metrics.
==64224== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==64224== Profiling result:
==64224== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (1)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         52                  eligible_warps_per_cycle           Eligible Warps Per Active Cycle    1.019701    1.025235    1.022578
         52                    dram_read_transactions           Device Memory Read Transactions     4324440     4331747     4325094
         52                      dram_read_throughput             Device Memory Read Throughput  19.176GB/s  19.288GB/s  19.254GB/s
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 32.593309 msec
Performance= 65.89 GFlop/s, Time= 32.593 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==64320== NVPROF is profiling process 64320, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==64320== Some kernel(s) will be replayed on device 1 in order to collect all events/metrics.
==64320== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==64320== Profiling result:
==64320== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (1)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         52                   dram_write_transactions          Device Memory Write Transactions      155302      159581      159180
         52                     dram_write_throughput            Device Memory Write Throughput  706.05MB/s  727.91MB/s  723.84MB/s
         52                      l2_read_transactions                      L2 Read Transactions     8388679     8388983     8388831
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 36.956264 msec
Performance= 58.11 GFlop/s, Time= 36.956 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==29396== NVPROF is profiling process 29396, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==29396== Some kernel(s) will be replayed on device 1 in order to collect all events/metrics.
==29396== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==29396== Profiling result:
==29396== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (1)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         52                        l2_read_throughput                     L2 Throughput (Reads)  37.259GB/s  37.383GB/s  37.326GB/s
         52                     l2_write_transactions                     L2 Write Transactions      131078      131078      131078
         52                       l2_write_throughput                    L2 Throughput (Writes)  596.17MB/s  598.13MB/s  596.05MB/s
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 9.801637 msec
Performance= 219.09 GFlop/s, Time= 9.802 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==64948== NVPROF is profiling process 64948, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==64948== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==64948== Profiling result:
==64948== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (1)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         52                  shared_load_transactions                  Shared Load Transactions    50331648    50331648    50331648
         52                    shared_load_throughput             Shared Memory Load Throughput  896.01GB/s  908.24GB/s  903.00GB/s
         52                 shared_store_transactions                 Shared Store Transactions     2097152     2097152     2097152
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 13.281566 msec
Performance= 161.69 GFlop/s, Time= 13.282 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==62920== NVPROF is profiling process 62920, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==62920== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==62920== Profiling result:
==62920== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (1)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         52                   shared_store_throughput            Shared Memory Store Throughput  37.298GB/s  37.748GB/s  37.624GB/s
         52                         branch_efficiency                         Branch Efficiency     100.00%     100.00%     100.00%
         52                               cf_executed        Executed Control-Flow Instructions     1114112     1114112     1114112
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 527.251949 msec
Performance= 4.07 GFlop/s, Time= 527.252 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==65652== NVPROF is profiling process 65652, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==65652== Some kernel(s) will be replayed on device 1 in order to collect all events/metrics.
==65652== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==65652== Profiling result:
==65652== Metric result:
Invocations                               Metric Name                            Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (1)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         52                                 cf_issued              Issued Control-Flow Instructions     1114112     1114112     1114112
         52                             flop_count_sp   Floating Point Operations(Single Precision)  2147483648  2147483648  2147483648
         52                        flop_sp_efficiency                  FLOP Efficiency(Peak Single)       7.86%       7.93%       7.90%
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 54.694781 msec
Performance= 39.26 GFlop/s, Time= 54.695 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==58228== NVPROF is profiling process 58228, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==58228== Some kernel(s) will be replayed on device 1 in order to collect all events/metrics.
==58228== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==58228== Profiling result:
==58228== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (1)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         52                            gld_throughput                    Global Load Throughput  37.270GB/s  37.432GB/s  37.347GB/s
         52                          gld_transactions                  Global Load Transactions    16777216    16777216    16777216
         52                            gst_throughput                   Global Store Throughput  596.32MB/s  598.91MB/s  597.00MB/s
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 13.680582 msec
Performance= 156.97 GFlop/s, Time= 13.681 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==64112== NVPROF is profiling process 64112, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==64112== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==64112== Profiling result:
==64112== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (1)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         52                          gst_transactions                 Global Store Transactions      131072      131072      131072
         52                               inst_issued                       Instructions Issued    97852247    97852855    97852466
         52                             inst_per_warp                     Instructions per warp  2.9860e+03  2.9860e+03  2.9860e+03
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 10.625631 msec
Performance= 202.10 GFlop/s, Time= 10.626 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==65236== NVPROF is profiling process 65236, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==65236== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==65236== Profiling result:
==65236== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (1)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         52                                       ipc                              Executed IPC    0.930310    0.940486    0.937701
