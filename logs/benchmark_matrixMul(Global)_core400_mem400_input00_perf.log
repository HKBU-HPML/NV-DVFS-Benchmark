"arg:-wA=1024 -hA=1024 -wB=1024 -hB=1024" 
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
Adjust Iters to 997 for meeting time requirement 10 secs.
iterated 997, average time is 10.065181 msec
Performance= 213.36 GFlop/s, Time= 10.065 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 30.740335 msec.
GPU total   time: 1537.016731 ms
GPU average time: 30.740335 ms
Performance= 69.86 GFlop/s, Time= 30.740 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==42228== NVPROF is profiling process 42228, command: applications/matrixMul(Global) -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==42228== Warning: Unified Memory Profiling is not supported on the current configuration because a pair of devices without peer-to-peer support is detected on this multi-GPU setup. When peer mappings are not available, system falls back to using zero-copy memory. It can cause kernels, which access unified memory, to run slower. More details can be found at: http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#um-managed-memory
==42228== Profiling application: applications/matrixMul(Global) -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==42228== Profiling result:
Time(%)      Time     Calls       Avg       Min       Max  Name
 99.69%  1.59392s        52  30.652ms  30.581ms  30.732ms  void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
  0.20%  3.2486ms         2  1.6243ms  1.5781ms  1.6705ms  [CUDA memcpy HtoD]
  0.11%  1.7731ms         1  1.7731ms  1.7731ms  1.7731ms  [CUDA memcpy DtoH]

==42228== API calls:
Time(%)      Time     Calls       Avg       Min       Max  Name
 84.05%  1.56730s        51  30.731ms  30.650ms  30.935ms  cudaThreadSynchronize
  9.84%  183.52ms         3  61.174ms  1.0990ms  181.32ms  cudaMalloc
  3.66%  68.187ms         1  68.187ms  68.187ms  68.187ms  cudaDeviceReset
  1.69%  31.498ms         3  10.499ms  7.1070us  31.484ms  cudaDeviceSynchronize
  0.30%  5.5784ms         3  1.8595ms  1.2542ms  2.3674ms  cudaMemcpy
  0.20%  3.7037ms        51  72.621us  34.680us  240.20us  cudaEventSynchronize
  0.06%  1.0427ms       182  5.7290us       0ns  283.98us  cuDeviceGetAttribute
  0.05%  931.53us        52  17.914us  15.066us  54.294us  cudaLaunch
  0.05%  904.24us       102  8.8650us  5.1160us  28.711us  cudaEventRecord
  0.03%  565.40us         1  565.40us  565.40us  565.40us  cudaGetDeviceProperties
  0.03%  471.03us         3  157.01us  117.69us  188.18us  cudaFree
  0.02%  425.54us        51  8.3440us  7.6750us  20.751us  cudaEventElapsedTime
  0.01%  178.80us         2  89.401us  68.792us  110.01us  cuDeviceGetName
  0.01%  156.34us       260     601ns       0ns  11.371us  cudaSetupArgument
  0.00%  82.155us        52  1.5790us     284ns  11.655us  cudaConfigureCall
  0.00%  50.883us         1  50.883us  50.883us  50.883us  cudaSetDevice
  0.00%  12.224us         2  6.1120us  5.4010us  6.8230us  cuDeviceTotalMem
  0.00%  6.8220us         2  3.4110us  1.1370us  5.6850us  cudaEventCreate
  0.00%  3.1280us         3  1.0420us     285ns  2.5580us  cuDeviceGetCount
  0.00%  2.8430us         1  2.8430us  2.8430us  2.8430us  cudaGetDevice
  0.00%  2.2740us         6     379ns       0ns     853ns  cuDeviceGet
