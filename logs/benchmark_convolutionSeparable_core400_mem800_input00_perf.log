"arg:" 
[applications\convolutionSeparable] - Starting...
gpuDeviceInit() CUDA Device [1]: "GeForce GTX 980
Image Width x Height = 3072 x 3072

Allocating and initializing host arrays...
Allocating and initializing CUDA arrays...
Running GPU convolution (100 identical iterations)...

Adjust Iters to 2673 for meeting time requirement 10 secs.
iterated 2673, average time is 3.737574 msec.

Reading back GPU results...

Checking the results...
 ...running convolutionRowCPU()
 ...running convolutionColumnCPU()
 ...comparing the results
 ...Relative L2 norm: 0.000000E+000

Shutting down...
Test passed
[applications/convolutionSeparable] - Starting...
gpuDeviceInit() CUDA Device [1]: "GeForce GTX 980
Image Width x Height = 3072 x 3072

Allocating and initializing host arrays...
Allocating and initializing CUDA arrays...
Running GPU convolution (50 identical iterations)...

iterated 50, average time is 3.738735 msec.

Reading back GPU results...

Checking the results...
 ...running convolutionRowCPU()
 ...running convolutionColumnCPU()
 ...comparing the results
 ...Relative L2 norm: 0.000000E+000

Shutting down...
Test passed
==83892== NVPROF is profiling process 83892, command: applications/convolutionSeparable -device=1 -iters=50
==83892== Warning: Unified Memory Profiling is not supported on the current configuration because a pair of devices without peer-to-peer support is detected on this multi-GPU setup. When peer mappings are not available, system falls back to using zero-copy memory. It can cause kernels, which access unified memory, to run slower. More details can be found at: http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#um-managed-memory
==83892== Profiling application: applications/convolutionSeparable -device=1 -iters=50
==83892== Profiling result:
Time(%)      Time     Calls       Avg       Min       Max  Name
 44.04%  97.159ms        51  1.9051ms  1.8931ms  1.9149ms  convolutionColumnsKernel(float*, float*, int, int, int)
 40.42%  89.166ms        51  1.7483ms  1.7448ms  1.7537ms  convolutionRowsKernel(float*, float*, int, int, int)
  8.03%  17.718ms         1  17.718ms  17.718ms  17.718ms  [CUDA memcpy DtoH]
  7.50%  16.548ms         2  8.2740ms  2.9760us  16.545ms  [CUDA memcpy HtoD]

==83892== API calls:
Time(%)      Time     Calls       Avg       Min       Max  Name
 40.86%  210.73ms         3  70.245ms  7.0017ms  196.61ms  cudaMalloc
 37.19%  191.79ms        51  3.7606ms  3.7193ms  4.4826ms  cudaThreadSynchronize
 13.39%  69.051ms         1  69.051ms  69.051ms  69.051ms  cudaDeviceReset
  6.63%  34.205ms         2  17.103ms  16.053ms  18.152ms  cudaMemcpy
  0.61%  3.1497ms        51  61.757us  46.051us  80.731us  cudaEventSynchronize
  0.33%  1.6914ms         3  563.79us  498.60us  663.19us  cudaFree
  0.32%  1.6738ms       102  16.409us  14.213us  71.350us  cudaLaunch
  0.21%  1.0737ms       182  5.8990us       0ns  306.44us  cuDeviceGetAttribute
  0.16%  836.02us       102  8.1960us  5.9690us  19.046us  cudaEventRecord
  0.12%  618.56us         1  618.56us  618.56us  618.56us  cudaGetDeviceProperties
  0.10%  491.50us        51  9.6370us  9.3800us  10.518us  cudaEventElapsedTime
  0.03%  148.96us         2  74.477us  69.361us  79.594us  cuDeviceGetName
  0.02%  97.786us       510     191ns       0ns  1.4220us  cudaSetupArgument
  0.01%  42.640us         1  42.640us  42.640us  42.640us  cudaMemcpyToSymbol
  0.01%  38.089us       102     373ns       0ns  3.9800us  cudaConfigureCall
  0.01%  27.860us       102     273ns       0ns     569ns  cudaGetLastError
  0.00%  16.203us         2  8.1010us  5.4010us  10.802us  cuDeviceTotalMem
  0.00%  15.350us         2  7.6750us  1.1370us  14.213us  cudaEventCreate
  0.00%  14.782us         2  7.3910us  7.3910us  7.3910us  cudaDeviceSynchronize
  0.00%  10.802us         1  10.802us  10.802us  10.802us  cudaSetDevice
  0.00%  3.1260us         3  1.0420us     284ns  2.5580us  cuDeviceGetCount
  0.00%  2.2760us         6     379ns       0ns     569ns  cuDeviceGet
  0.00%     853ns         1     853ns     853ns     853ns  cudaGetDeviceCount
