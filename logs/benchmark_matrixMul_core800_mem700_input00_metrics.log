[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 15, average time is 5.380209 msec
Performance= 399.15 GFlop/s, Time= 5.380 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==10548== NVPROF is profiling process 10548, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==10548== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==10548== Profiling result:
   Start  Duration            Grid Size      Block Size     Regs*    SSMem*    DSMem*      Size  Throughput           Device   Context    Stream  Name
216.45ms  1.4532ms                    -               -         -         -         -  4.0000MB  2.6881GB/s  GeForce GTX 980         1         7  [CUDA memcpy HtoD]
218.23ms  1.5102ms                    -               -         -         -         -  4.0000MB  2.5866GB/s  GeForce GTX 980         1         7  [CUDA memcpy HtoD]
219.75ms  5.2987ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [114]
225.17ms  5.2801ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [125]
230.65ms  5.2754ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [138]
236.11ms  5.3199ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [150]
241.61ms  5.2690ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [162]
247.15ms  5.3467ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [174]
252.68ms  5.2683ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [186]
258.13ms  5.2927ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [198]
263.60ms  5.2886ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [210]
269.07ms  5.2728ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [222]
274.59ms  5.2710ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [234]
280.05ms  5.3144ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [246]
285.54ms  5.2790ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [258]
291.01ms  5.3179ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [270]
296.50ms  5.2871ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [282]
301.97ms  5.3255ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [294]
307.48ms  5.3062ms            (32 32 1)       (32 32 1)        28  8.0000KB        0B         -           -  GeForce GTX 980         1         7  void matrixMulCUDA<int=32>(float*, float*, float*, int, int) [306]
312.97ms  2.0802ms                    -               -         -         -         -  4.0000MB  1.8778GB/s  GeForce GTX 980         1         7  [CUDA memcpy DtoH]

Regs: Number of registers used per CUDA thread. This number includes registers used internally by the CUDA driver and/or tools and can be more than what the compiler shows.
SSMem: Static shared memory allocated per CUDA block.
DSMem: Dynamic shared memory allocated per CUDA block.
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 15, average time is 12.018086 msec
Performance= 178.69 GFlop/s, Time= 12.018 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==11048== NVPROF is profiling process 11048, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==11048== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==11048== Profiling result:
==11048== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         17                        achieved_occupancy                        Achieved Occupancy    0.994174    0.995415    0.995053
         17                             sm_efficiency                   Multiprocessor Activity      98.50%      99.53%      99.11%
         17                 warp_execution_efficiency                 Warp Execution Efficiency     100.00%     100.00%     100.00%
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 15, average time is 28.156245 msec
Performance= 76.27 GFlop/s, Time= 28.156 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==9368== NVPROF is profiling process 9368, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==9368== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==9368== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==9368== Profiling result:
==9368== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         17                  eligible_warps_per_cycle           Eligible Warps Per Active Cycle    1.743293    1.748333    1.745756
         17                    dram_read_transactions           Device Memory Read Transactions     4325271     4325543     4325425
         17                      dram_read_throughput             Device Memory Read Throughput  24.281GB/s  24.392GB/s  24.339GB/s
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 15, average time is 25.818376 msec
Performance= 83.18 GFlop/s, Time= 25.818 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==5168== NVPROF is profiling process 5168, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==5168== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==5168== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==5168== Profiling result:
==5168== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         17                   dram_write_transactions          Device Memory Write Transactions      157343      160084      159606
         17                     dram_write_throughput            Device Memory Write Throughput  906.46MB/s  924.03MB/s  918.39MB/s
         17                      l2_read_transactions                      L2 Read Transactions     8388679     8389065     8388795
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 15, average time is 28.951305 msec
Performance= 74.18 GFlop/s, Time= 28.951 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==9420== NVPROF is profiling process 9420, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==9420== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==9420== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==9420== Profiling result:
==9420== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         17                        l2_read_throughput                     L2 Throughput (Reads)  46.981GB/s  47.282GB/s  47.144GB/s
         17                     l2_write_transactions                     L2 Write Transactions      131078      131078      131078
         17                       l2_write_throughput                    L2 Throughput (Writes)  751.72MB/s  756.51MB/s  753.40MB/s
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 15, average time is 8.050865 msec
Performance= 266.74 GFlop/s, Time= 8.051 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==2280== NVPROF is profiling process 2280, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==2280== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==2280== Profiling result:
==2280== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         17                  shared_load_transactions                  Shared Load Transactions    50331648    50331648    50331648
         17                    shared_load_throughput             Shared Memory Load Throughput  1123.4GB/s  1139.2GB/s  1131.9GB/s
         17                 shared_store_transactions                 Shared Store Transactions     2097152     2097152     2097152
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 15, average time is 11.409735 msec
Performance= 188.22 GFlop/s, Time= 11.410 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==11180== NVPROF is profiling process 11180, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==11180== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==11180== Profiling result:
==11180== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         17                   shared_store_throughput            Shared Memory Store Throughput  46.753GB/s  47.365GB/s  47.150GB/s
         17                         branch_efficiency                         Branch Efficiency     100.00%     100.00%     100.00%
         17                               cf_executed        Executed Control-Flow Instructions     1114112     1114112     1114112
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 15, average time is 335.503955 msec
Performance= 6.40 GFlop/s, Time= 335.504 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==8780== NVPROF is profiling process 8780, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==8780== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==8780== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==8780== Profiling result:
==8780== Metric result:
Invocations                               Metric Name                            Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         17                                 cf_issued              Issued Control-Flow Instructions     1114112     1114112     1114112
         17                             flop_count_sp   Floating Point Operations(Single Precision)  2147483648  2147483648  2147483648
         17                        flop_sp_efficiency                  FLOP Efficiency(Peak Single)      12.55%      12.68%      12.61%
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 15, average time is 42.895765 msec
Performance= 50.06 GFlop/s, Time= 42.896 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==11192== NVPROF is profiling process 11192, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==11192== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==11192== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==11192== Profiling result:
==11192== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         17                            gld_throughput                    Global Load Throughput  46.936GB/s  47.346GB/s  47.181GB/s
         17                          gld_transactions                  Global Load Transactions    16777216    16777216    16777216
         17                            gst_throughput                   Global Store Throughput  750.98MB/s  757.53MB/s  754.36MB/s
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 15, average time is 11.686492 msec
Performance= 183.76 GFlop/s, Time= 11.686 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==10324== NVPROF is profiling process 10324, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==10324== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==10324== Profiling result:
==10324== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         17                          gst_transactions                 Global Store Transactions      131072      131072      131072
         17                               inst_issued                       Instructions Issued    97850684    97850972    97850807
         17                             inst_per_warp                     Instructions per warp  2.9860e+03  2.9860e+03  2.9860e+03
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 15, average time is 8.780115 msec
Performance= 244.58 GFlop/s, Time= 8.780 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==11192== NVPROF is profiling process 11192, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==11192== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=0 -iters=15
==11192== Profiling result:
==11192== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (0)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         17                                       ipc                              Executed IPC    1.481810    1.490287    1.486653
