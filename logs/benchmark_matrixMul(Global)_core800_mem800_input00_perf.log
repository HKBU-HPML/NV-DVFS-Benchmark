"arg:-wA=1024 -hA=1024 -wB=1024 -hB=1024" 
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
Adjust Iters to 1934 for meeting time requirement 10 secs.
iterated 1934, average time is 5.218406 msec
Performance= 411.52 GFlop/s, Time= 5.218 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 15.530106 msec.
GPU total   time: 776.505314 ms
GPU average time: 15.530106 ms
Performance= 138.28 GFlop/s, Time= 15.530 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==11832== NVPROF is profiling process 11832, command: applications/matrixMul(Global) -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==11832== Warning: Unified Memory Profiling is not supported on the current configuration because a pair of devices without peer-to-peer support is detected on this multi-GPU setup. When peer mappings are not available, system falls back to using zero-copy memory. It can cause kernels, which access unified memory, to run slower. More details can be found at: http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#um-managed-memory
==11832== Profiling application: applications/matrixMul(Global) -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==11832== Profiling result:
Time(%)      Time     Calls       Avg       Min       Max  Name
 99.38%  803.00ms        52  15.442ms  15.407ms  15.469ms  void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
  0.41%  3.3230ms         2  1.6615ms  1.6196ms  1.7035ms  [CUDA memcpy HtoD]
  0.20%  1.6531ms         1  1.6531ms  1.6531ms  1.6531ms  [CUDA memcpy DtoH]

==11832== API calls:
Time(%)      Time     Calls       Avg       Min       Max  Name
 73.99%  791.85ms        51  15.527ms  15.481ms  15.575ms  cudaThreadSynchronize
 17.73%  189.75ms         3  63.250ms  1.1834ms  187.38ms  cudaMalloc
  5.45%  58.368ms         1  58.368ms  58.368ms  58.368ms  cudaDeviceReset
  1.52%  16.249ms         3  5.4165ms  7.3910us  16.235ms  cudaDeviceSynchronize
  0.51%  5.4226ms         3  1.8075ms  1.2741ms  2.1308ms  cudaMemcpy
  0.34%  3.6551ms        51  71.668us  55.715us  138.44us  cudaEventSynchronize
  0.10%  1.0657ms       182  5.8550us       0ns  292.51us  cuDeviceGetAttribute
  0.09%  988.39us        52  19.007us  15.066us  54.010us  cudaLaunch
  0.07%  760.69us       102  7.4570us  4.8320us  25.016us  cudaEventRecord
  0.06%  642.15us         3  214.05us  199.55us  229.97us  cudaFree
  0.06%  598.09us         1  598.09us  598.09us  598.09us  cudaGetDeviceProperties
  0.04%  457.67us        51  8.9730us  7.9590us  10.802us  cudaEventElapsedTime
  0.02%  184.49us         2  92.244us  69.645us  114.84us  cuDeviceGetName
  0.01%  154.64us       260     594ns       0ns  11.655us  cudaSetupArgument
  0.00%  47.187us        52     907ns     284ns  11.371us  cudaConfigureCall
  0.00%  14.213us         1  14.213us  14.213us  14.213us  cudaSetDevice
  0.00%  11.939us         2  5.9690us  5.4010us  6.5380us  cuDeviceTotalMem
  0.00%  6.5380us         2  3.2690us  1.1370us  5.4010us  cudaEventCreate
  0.00%  3.1280us         6     521ns     284ns  1.1370us  cuDeviceGet
  0.00%  3.1270us         3  1.0420us     284ns  2.5590us  cuDeviceGetCount
  0.00%  2.5590us         1  2.5590us  2.5590us  2.5590us  cudaGetDevice
