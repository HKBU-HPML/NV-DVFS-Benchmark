[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 17.749201 msec
Performance= 120.99 GFlop/s, Time= 17.749 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==67964== NVPROF is profiling process 67964, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==67964== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==67964== Profiling result:
==67964== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (1)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         52                        achieved_occupancy                        Achieved Occupancy    0.993164    0.994635    0.993837
         52                             sm_efficiency                   Multiprocessor Activity      99.32%      99.76%      99.51%
         52                 warp_execution_efficiency                 Warp Execution Efficiency     100.00%     100.00%     100.00%
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 42.943301 msec
Performance= 50.01 GFlop/s, Time= 42.943 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==68968== NVPROF is profiling process 68968, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==68968== Some kernel(s) will be replayed on device 1 in order to collect all events/metrics.
==68968== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==68968== Profiling result:
==68968== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (1)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         52                  eligible_warps_per_cycle           Eligible Warps Per Active Cycle    1.850913    1.856186    1.853508
         52                    dram_read_transactions           Device Memory Read Transactions     4325399     4325819     4325446
         52                      dram_read_throughput             Device Memory Read Throughput  13.417GB/s  13.472GB/s  13.450GB/s
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 40.059823 msec
Performance= 53.61 GFlop/s, Time= 40.060 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==68292== NVPROF is profiling process 68292, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==68292== Some kernel(s) will be replayed on device 1 in order to collect all events/metrics.
==68292== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==68292== Profiling result:
==68292== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (1)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         52                   dram_write_transactions          Device Memory Write Transactions      154359      159761      159399
         52                     dram_write_throughput            Device Memory Write Throughput  491.69MB/s  509.28MB/s  506.40MB/s
         52                      l2_read_transactions                      L2 Read Transactions     8388679     8389119     8388829
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 44.220919 msec
Performance= 48.56 GFlop/s, Time= 44.221 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==68504== NVPROF is profiling process 68504, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==68504== Some kernel(s) will be replayed on device 1 in order to collect all events/metrics.
==68504== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==68504== Profiling result:
==68504== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (1)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         52                        l2_read_throughput                     L2 Throughput (Reads)  26.043GB/s  26.151GB/s  26.088GB/s
         52                     l2_write_transactions                     L2 Write Transactions      131078      131078      131078
         52                       l2_write_throughput                    L2 Throughput (Writes)  416.70MB/s  418.42MB/s  416.76MB/s
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 12.881155 msec
Performance= 166.72 GFlop/s, Time= 12.881 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==67128== NVPROF is profiling process 67128, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==67128== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==67128== Profiling result:
==67128== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (1)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         52                  shared_load_transactions                  Shared Load Transactions    50331648    50331648    50331648
         52                    shared_load_throughput             Shared Memory Load Throughput  624.22GB/s  627.68GB/s  626.36GB/s
         52                 shared_store_transactions                 Shared Store Transactions     2097152     2097152     2097152
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 16.389550 msec
Performance= 131.03 GFlop/s, Time= 16.390 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==69104== NVPROF is profiling process 69104, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==69104== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==69104== Profiling result:
==69104== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (1)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         52                   shared_store_throughput            Shared Memory Store Throughput  25.985GB/s  26.164GB/s  26.092GB/s
         52                         branch_efficiency                         Branch Efficiency     100.00%     100.00%     100.00%
         52                               cf_executed        Executed Control-Flow Instructions     1114112     1114112     1114112
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 434.766910 msec
Performance= 4.94 GFlop/s, Time= 434.767 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==68984== NVPROF is profiling process 68984, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==68984== Some kernel(s) will be replayed on device 1 in order to collect all events/metrics.
==68984== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==68984== Profiling result:
==68984== Metric result:
Invocations                               Metric Name                            Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (1)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         52                                 cf_issued              Issued Control-Flow Instructions     1114112     1114112     1114112
         52                             flop_count_sp   Floating Point Operations(Single Precision)  2147483648  2147483648  2147483648
         52                        flop_sp_efficiency                  FLOP Efficiency(Peak Single)      13.46%      13.54%      13.50%
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 64.387226 msec
Performance= 33.35 GFlop/s, Time= 64.387 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==83904== NVPROF is profiling process 83904, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==83904== Some kernel(s) will be replayed on device 1 in order to collect all events/metrics.
==83904== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==83904== Profiling result:
==83904== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (1)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         52                            gld_throughput                    Global Load Throughput  26.043GB/s  26.122GB/s  26.091GB/s
         52                          gld_transactions                  Global Load Transactions    16777216    16777216    16777216
         52                            gst_throughput                   Global Store Throughput  416.69MB/s  417.96MB/s  416.76MB/s
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 16.850646 msec
Performance= 127.44 GFlop/s, Time= 16.851 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==82368== NVPROF is profiling process 82368, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==82368== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==82368== Profiling result:
==82368== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (1)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         52                          gst_transactions                 Global Store Transactions      131072      131072      131072
         52                               inst_issued                       Instructions Issued    97850427    97851141    97850689
         52                             inst_per_warp                     Instructions per warp  2.9860e+03  2.9860e+03  2.9860e+03
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 13.710241 msec
Performance= 156.63 GFlop/s, Time= 13.710 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==84600== NVPROF is profiling process 84600, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==84600== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==84600== Profiling result:
==84600== Metric result:
Invocations                               Metric Name                        Metric Description         Min         Max         Avg
Device "GeForce GTX 980 (1)"
    Kernel: void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
         52                                       ipc                              Executed IPC    1.579872    1.585186    1.582999
