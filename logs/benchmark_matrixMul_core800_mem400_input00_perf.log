"arg:-wA=1024 -hA=1024 -wB=1024 -hB=1024" 
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
Adjust Iters to 1446 for meeting time requirement 10 secs.
iterated 1446, average time is 6.965870 msec
Performance= 308.29 GFlop/s, Time= 6.966 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 6.961796 msec
Performance= 308.47 GFlop/s, Time= 6.962 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==57000== NVPROF is profiling process 57000, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==57000== Warning: Unified Memory Profiling is not supported on the current configuration because a pair of devices without peer-to-peer support is detected on this multi-GPU setup. When peer mappings are not available, system falls back to using zero-copy memory. It can cause kernels, which access unified memory, to run slower. More details can be found at: http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#um-managed-memory
==57000== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==57000== Profiling result:
Time(%)      Time     Calls       Avg       Min       Max  Name
 98.51%  358.10ms        52  6.8865ms  6.8389ms  6.9275ms  void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
  0.89%  3.2334ms         2  1.6167ms  1.5766ms  1.6568ms  [CUDA memcpy HtoD]
  0.60%  2.1791ms         1  2.1791ms  2.1791ms  2.1791ms  [CUDA memcpy DtoH]

==57000== API calls:
Time(%)      Time     Calls       Avg       Min       Max  Name
 58.10%  355.20ms        51  6.9647ms  6.9099ms  7.0554ms  cudaThreadSynchronize
 28.34%  173.24ms         3  57.747ms  1.0904ms  171.05ms  cudaMalloc
 10.04%  61.362ms         1  61.362ms  61.362ms  61.362ms  cudaDeviceReset
  1.26%  7.6777ms         3  2.5592ms  6.5380us  7.6641ms  cudaDeviceSynchronize
  0.97%  5.9104ms         3  1.9701ms  1.2400ms  2.7224ms  cudaMemcpy
  0.50%  3.0848ms        51  60.486us  40.081us  133.32us  cudaEventSynchronize
  0.19%  1.1828ms       182  6.4990us       0ns  306.15us  cuDeviceGetAttribute
  0.16%  988.67us        52  19.012us  14.782us  53.726us  cudaLaunch
  0.12%  742.21us       102  7.2760us  4.8330us  20.467us  cudaEventRecord
  0.09%  565.97us         1  565.97us  565.97us  565.97us  cudaGetDeviceProperties
  0.08%  515.37us         3  171.79us  144.12us  186.19us  cudaFree
  0.07%  413.89us        51  8.1150us  7.6750us  10.802us  cudaEventElapsedTime
  0.04%  232.24us       260     893ns       0ns  11.655us  cudaSetupArgument
  0.03%  158.62us         2  79.310us  69.076us  89.544us  cuDeviceGetName
  0.01%  48.609us         1  48.609us  48.609us  48.609us  cudaSetDevice
  0.01%  47.184us        52     907ns     284ns  11.940us  cudaConfigureCall
  0.00%  11.370us         2  5.6850us  5.6850us  5.6850us  cuDeviceTotalMem
  0.00%  6.5390us         2  3.2690us     853ns  5.6860us  cudaEventCreate
  0.00%  3.4110us         3  1.1370us     284ns  2.5590us  cuDeviceGetCount
  0.00%  2.8420us         1  2.8420us  2.8420us  2.8420us  cudaGetDevice
  0.00%  1.9930us         6     332ns     284ns     569ns  cuDeviceGet
