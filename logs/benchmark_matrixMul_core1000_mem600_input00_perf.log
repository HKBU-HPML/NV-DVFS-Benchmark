"arg:-wA=1024 -hA=1024 -wB=1024 -hB=1024" 
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
Adjust Iters to 2080 for meeting time requirement 10 secs.
iterated 2080, average time is 4.882426 msec
Performance= 439.84 GFlop/s, Time= 4.882 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 4.893149 msec
Performance= 438.88 GFlop/s, Time= 4.893 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==86384== NVPROF is profiling process 86384, command: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==86384== Warning: Unified Memory Profiling is not supported on the current configuration because a pair of devices without peer-to-peer support is detected on this multi-GPU setup. When peer mappings are not available, system falls back to using zero-copy memory. It can cause kernels, which access unified memory, to run slower. More details can be found at: http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#um-managed-memory
==86384== Profiling application: applications/matrixMul -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==86384== Profiling result:
Time(%)      Time     Calls       Avg       Min       Max  Name
 97.73%  250.89ms        52  4.8248ms  4.7572ms  4.9002ms  void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
  1.26%  3.2371ms         2  1.6186ms  1.5760ms  1.6611ms  [CUDA memcpy HtoD]
  1.01%  2.5951ms         1  2.5951ms  2.5951ms  2.5951ms  [CUDA memcpy DtoH]

==86384== API calls:
Time(%)      Time     Calls       Avg       Min       Max  Name
 47.29%  249.67ms        51  4.8956ms  4.8262ms  4.9743ms  cudaThreadSynchronize
 36.41%  192.21ms         3  64.070ms  1.0865ms  190.03ms  cudaMalloc
 12.56%  66.309ms         1  66.309ms  66.309ms  66.309ms  cudaDeviceReset
  1.24%  6.5728ms         3  2.1909ms  1.2516ms  3.3751ms  cudaMemcpy
  1.07%  5.6458ms         3  1.8819ms  7.1070us  5.6313ms  cudaDeviceSynchronize
  0.54%  2.8327ms        51  55.543us  29.564us  115.13us  cudaEventSynchronize
  0.21%  1.1083ms       182  6.0890us       0ns  311.27us  cuDeviceGetAttribute
  0.17%  891.74us        52  17.148us  14.781us  54.011us  cudaLaunch
  0.15%  767.51us       102  7.5240us  4.8320us  16.772us  cudaEventRecord
  0.12%  616.85us         1  616.85us  616.85us  616.85us  cudaGetDeviceProperties
  0.09%  463.92us         3  154.64us  118.82us  181.65us  cudaFree
  0.08%  426.40us        51  8.3600us  7.6750us  22.741us  cudaEventElapsedTime
  0.03%  158.05us         2  79.025us  68.792us  89.259us  cuDeviceGetName
  0.03%  154.36us       260     593ns       0ns  11.655us  cudaSetupArgument
  0.01%  68.221us        52  1.3110us     284ns  11.940us  cudaConfigureCall
  0.00%  12.791us         1  12.791us  12.791us  12.791us  cudaSetDevice
  0.00%  11.370us         2  5.6850us  5.6850us  5.6850us  cuDeviceTotalMem
  0.00%  7.3910us         2  3.6950us  1.1370us  6.2540us  cudaEventCreate
  0.00%  3.1260us         3  1.0420us     284ns  2.2740us  cuDeviceGetCount
  0.00%  2.5580us         6     426ns     284ns     569ns  cuDeviceGet
  0.00%  2.2740us         1  2.2740us  2.2740us  2.2740us  cudaGetDevice
