"arg:-wA=1024 -hA=1024 -wB=1024 -hB=1024" 
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
Adjust Iters to 1318 for meeting time requirement 10 secs.
iterated 1318, average time is 7.576723 msec
Performance= 283.43 GFlop/s, Time= 7.577 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 21.321076 msec.
GPU total   time: 1066.053795 ms
GPU average time: 21.321076 ms
Performance= 100.72 GFlop/s, Time= 21.321 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==45512== NVPROF is profiling process 45512, command: applications/matrixMul(Global) -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==45512== Warning: Unified Memory Profiling is not supported on the current configuration because a pair of devices without peer-to-peer support is detected on this multi-GPU setup. When peer mappings are not available, system falls back to using zero-copy memory. It can cause kernels, which access unified memory, to run slower. More details can be found at: http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#um-managed-memory
==45512== Profiling application: applications/matrixMul(Global) -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==45512== Profiling result:
Time(%)      Time     Calls       Avg       Min       Max  Name
 99.55%  1.10395s        52  21.230ms  21.197ms  21.276ms  void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
  0.30%  3.3372ms         2  1.6686ms  1.6357ms  1.7014ms  [CUDA memcpy HtoD]
  0.15%  1.7028ms         1  1.7028ms  1.7028ms  1.7028ms  [CUDA memcpy DtoH]

==45512== API calls:
Time(%)      Time     Calls       Avg       Min       Max  Name
 78.95%  1.08684s        51  21.311ms  21.275ms  21.352ms  cudaThreadSynchronize
 13.90%  191.32ms         3  63.773ms  1.1251ms  189.07ms  cudaMalloc
  4.52%  62.259ms         1  62.259ms  62.259ms  62.259ms  cudaDeviceReset
  1.60%  22.037ms         3  7.3456ms  7.1070us  22.022ms  cudaDeviceSynchronize
  0.40%  5.4442ms         3  1.8147ms  1.3105ms  2.1422ms  cudaMemcpy
  0.28%  3.7995ms        51  74.499us  38.660us  189.60us  cudaEventSynchronize
  0.08%  1.0433ms       182  5.7320us       0ns  292.79us  cuDeviceGetAttribute
  0.07%  1.0026ms        52  19.280us  14.782us  64.812us  cudaLaunch
  0.06%  789.40us       102  7.7390us  4.8320us  23.594us  cudaEventRecord
  0.04%  571.94us         3  190.65us  136.73us  219.45us  cudaFree
  0.04%  563.98us         1  563.98us  563.98us  563.98us  cudaGetDeviceProperties
  0.03%  449.14us        51  8.8060us  7.9590us  10.518us  cudaEventElapsedTime
  0.01%  171.98us         2  85.990us  69.361us  102.62us  cuDeviceGetName
  0.01%  138.72us       260     533ns       0ns  11.371us  cudaSetupArgument
  0.00%  50.025us        52     962ns     284ns  11.655us  cudaConfigureCall
  0.00%  46.335us         1  46.335us  46.335us  46.335us  cudaSetDevice
  0.00%  11.371us         2  5.6850us  5.4010us  5.9700us  cuDeviceTotalMem
  0.00%  6.5380us         2  3.2690us     853ns  5.6850us  cudaEventCreate
  0.00%  3.4110us         3  1.1370us     284ns  2.5590us  cuDeviceGetCount
  0.00%  2.8430us         1  2.8430us  2.8430us  2.8430us  cudaGetDevice
  0.00%  2.2750us         6     379ns       0ns     853ns  cuDeviceGet
