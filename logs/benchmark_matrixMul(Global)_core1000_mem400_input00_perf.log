"arg:-wA=1024 -hA=1024 -wB=1024 -hB=1024" 
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
Adjust Iters to 1493 for meeting time requirement 10 secs.
iterated 1493, average time is 6.721481 msec
Performance= 319.50 GFlop/s, Time= 6.721 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 15.571309 msec.
GPU total   time: 778.565470 ms
GPU average time: 15.571309 ms
Performance= 137.91 GFlop/s, Time= 15.571 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==55724== NVPROF is profiling process 55724, command: applications/matrixMul(Global) -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==55724== Warning: Unified Memory Profiling is not supported on the current configuration because a pair of devices without peer-to-peer support is detected on this multi-GPU setup. When peer mappings are not available, system falls back to using zero-copy memory. It can cause kernels, which access unified memory, to run slower. More details can be found at: http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#um-managed-memory
==55724== Profiling application: applications/matrixMul(Global) -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==55724== Profiling result:
Time(%)      Time     Calls       Avg       Min       Max  Name
 99.40%  805.47ms        52  15.490ms  15.456ms  15.548ms  void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
  0.40%  3.2300ms         2  1.6150ms  1.5681ms  1.6619ms  [CUDA memcpy HtoD]
  0.20%  1.6152ms         1  1.6152ms  1.6152ms  1.6152ms  [CUDA memcpy DtoH]

==55724== API calls:
Time(%)      Time     Calls       Avg       Min       Max  Name
 73.80%  793.80ms        51  15.565ms  15.515ms  15.658ms  cudaThreadSynchronize
 17.65%  189.80ms         3  63.267ms  1.1516ms  187.48ms  cudaMalloc
  5.79%  62.300ms         1  62.300ms  62.300ms  62.300ms  cudaDeviceReset
  1.52%  16.304ms         3  5.4346ms  7.1070us  16.279ms  cudaDeviceSynchronize
  0.48%  5.1540ms         3  1.7180ms  1.2499ms  1.9776ms  cudaMemcpy
  0.31%  3.3856ms        51  66.384us  39.513us  142.70us  cudaEventSynchronize
  0.10%  1.0990ms       182  6.0380us       0ns  318.38us  cuDeviceGetAttribute
  0.09%  959.39us        52  18.449us  15.634us  54.579us  cudaLaunch
  0.08%  841.15us       102  8.2460us  5.1160us  24.447us  cudaEventRecord
  0.05%  550.34us         1  550.34us  550.34us  550.34us  cudaGetDeviceProperties
  0.05%  525.89us         3  175.30us  121.67us  206.66us  cudaFree
  0.04%  421.00us        51  8.2540us  7.9590us  10.802us  cudaEventElapsedTime
  0.02%  176.52us       260     678ns       0ns  11.939us  cudaSetupArgument
  0.02%  166.29us         2  83.147us  68.792us  97.502us  cuDeviceGetName
  0.01%  94.658us        52  1.8200us     284ns  11.655us  cudaConfigureCall
  0.00%  14.497us         1  14.497us  14.497us  14.497us  cudaSetDevice
  0.00%  12.223us         2  6.1110us  5.4010us  6.8220us  cuDeviceTotalMem
  0.00%  6.8210us         2  3.4100us     852ns  5.9690us  cudaEventCreate
  0.00%  3.4120us         3  1.1370us     284ns  2.8430us  cuDeviceGetCount
  0.00%  2.8440us         6     474ns       0ns  1.1370us  cuDeviceGet
  0.00%  2.5580us         1  2.5580us  2.5580us  2.5580us  cudaGetDevice
