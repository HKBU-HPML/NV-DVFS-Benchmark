"arg:-wA=1024 -hA=1024 -wB=1024 -hB=1024" 
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
Adjust Iters to 1052 for meeting time requirement 10 secs.
iterated 1052, average time is 9.543579 msec
Performance= 225.02 GFlop/s, Time= 9.544 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
[Matrix Multiply Using CUDA] - Starting...
GPU Device 1: "GeForce GTX 980" with compute capability 5.2

MatrixA(1024,1024), MatrixB(1024,1024)
Computing result using CUDA Kernel...
done
iterated 50, average time is 30.476288 msec.
GPU total   time: 1523.814396 ms
GPU average time: 30.476288 ms
Performance= 70.46 GFlop/s, Time= 30.476 msec, Size= 2147483648 Ops, WorkgroupSize= 1024 threads/block
Checking computed result for correctness: Result = PASS

Note: For peak performance, please refer to the matrixMulCUBLAS example.
==9776== NVPROF is profiling process 9776, command: applications/matrixMul(Global) -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==9776== Warning: Unified Memory Profiling is not supported on the current configuration because a pair of devices without peer-to-peer support is detected on this multi-GPU setup. When peer mappings are not available, system falls back to using zero-copy memory. It can cause kernels, which access unified memory, to run slower. More details can be found at: http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#um-managed-memory
==9776== Profiling application: applications/matrixMul(Global) -wA=1024 -hA=1024 -wB=1024 -hB=1024 -device=1 -iters=50
==9776== Profiling result:
Time(%)      Time     Calls       Avg       Min       Max  Name
 99.69%  1.57914s        52  30.368ms  30.321ms  30.406ms  void matrixMulCUDA<int=32>(float*, float*, float*, int, int)
  0.21%  3.2811ms         2  1.6406ms  1.5950ms  1.6861ms  [CUDA memcpy HtoD]
  0.11%  1.6845ms         1  1.6845ms  1.6845ms  1.6845ms  [CUDA memcpy DtoH]

==9776== API calls:
Time(%)      Time     Calls       Avg       Min       Max  Name
 83.81%  1.55369s        51  30.465ms  30.411ms  30.562ms  cudaThreadSynchronize
 10.16%  188.39ms         3  62.798ms  1.1291ms  186.13ms  cudaMalloc
  3.55%  65.737ms         1  65.737ms  65.737ms  65.737ms  cudaDeviceReset
  1.68%  31.172ms         3  10.391ms  7.6750us  31.156ms  cudaDeviceSynchronize
  0.29%  5.3740ms         3  1.7913ms  1.2786ms  2.1175ms  cudaMemcpy
  0.25%  4.5559ms        51  89.331us  63.675us  231.11us  cudaEventSynchronize
  0.06%  1.0774ms       182  5.9190us       0ns  302.46us  cuDeviceGetAttribute
  0.05%  994.93us        52  19.133us  15.919us  54.295us  cudaLaunch
  0.04%  808.45us       102  7.9250us  5.1160us  29.563us  cudaEventRecord
  0.03%  637.32us         3  212.44us  183.92us  235.09us  cudaFree
  0.03%  608.61us         1  608.61us  608.61us  608.61us  cudaGetDeviceProperties
  0.03%  500.02us        51  9.8040us  7.6750us  20.751us  cudaEventElapsedTime
  0.01%  184.49us         2  92.244us  69.076us  115.41us  cuDeviceGetName
  0.00%  65.379us       260     251ns       0ns  11.939us  cudaSetupArgument
  0.00%  29.564us        52     568ns     284ns  4.8330us  cudaConfigureCall
  0.00%  14.498us         1  14.498us  14.498us  14.498us  cudaSetDevice
  0.00%  11.939us         2  5.9690us  5.4010us  6.5380us  cuDeviceTotalMem
  0.00%  7.3910us         2  3.6950us  1.1370us  6.2540us  cudaEventCreate
  0.00%  3.4120us         6     568ns     284ns  1.1370us  cuDeviceGet
  0.00%  3.4110us         3  1.1370us     284ns  2.8420us  cuDeviceGetCount
  0.00%  2.8430us         1  2.8430us  2.8430us  2.8430us  cudaGetDevice
